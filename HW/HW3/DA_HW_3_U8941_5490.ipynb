{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DA_HW_3_U8941-5490.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "bQVbSTr-52Nb",
        "m5vdClgiC3af",
        "g5atfnJVYmov",
        "9V18rn37hEzV",
        "44W9Ly7rV8sM"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umLqDib8FZ_M",
        "outputId": "8bbec415-bde9-47c9-8690-b0cc4392fb22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "aWuBpiNKFesi"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/Dataset/DA/HW3/breast-cancer-wisconsin.csv\"\n",
        "\n",
        "df_data = pd.read_csv(file_path, header=None, names = ['ID', 'x0', 'x1', 'x2', 'x3','x4','x5','x6','x7', 'x8', 'Label'])\n"
      ],
      "metadata": {
        "id": "5Rm8_SAPFgb1"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_data.dropna()\n",
        "\n",
        "df_train_data = df_data.iloc[:400, 1:-1]\n",
        "df_test_data = df_data.iloc[400:,1:-1]\n",
        "\n",
        "\n",
        "train_data = df_train_data.values\n",
        "test_data = df_test_data.values\n",
        "\n",
        "train_label = df_data.iloc[0:400, 10].values\n",
        "test_label = df_data.iloc[400:,10].values\n",
        "\n",
        "train_label = (train_label/2) -1\n",
        "test_label = (test_label/2) -1\n",
        "\n",
        "print(train_data.shape)\n",
        "\n",
        "print(train_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjSmIkt2GHbH",
        "outputId": "3c5a60af-925b-4103-a617-4a2c3bb80f34"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(400, 9)\n",
            "[[ 5  1  1 ...  3  1  1]\n",
            " [ 5  4  4 ...  3  2  1]\n",
            " [ 3  1  1 ...  3  1  1]\n",
            " ...\n",
            " [10 10 10 ...  8  5  1]\n",
            " [ 5  1  2 ...  3  1  1]\n",
            " [ 8  5  6 ...  6  6  1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Functions to calculate Miss Classification Rate and RMS margin**"
      ],
      "metadata": {
        "id": "RztEyKYbI82Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def miss_classification_rate(test_pred):\n",
        "  comparison = np.equal(test_label, test_pred)\n",
        "  MCR = 1 - np.count_nonzero(comparison)/test_data.shape[0]\n",
        "\n",
        "  return MCR, comparison\n",
        "\n",
        "def RMS_func(correct_classified_prob):\n",
        "  M_c = correct_classified_prob.shape[0]\n",
        "  RMS = np.sqrt(((1/M_c) * np.sum( (correct_classified_prob-0.5)**2) ) )\n",
        "\n",
        "  return RMS\n",
        "\n"
      ],
      "metadata": {
        "id": "H2oZx1AlA2LC"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Function to Calculate Weighted Cost**"
      ],
      "metadata": {
        "id": "PuG2dPPBZOua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Weighted cost\n",
        "\n",
        "def weighted_cost(comp_ar):\n",
        "  \n",
        "  incorrect_indices = np.where(comp_ar == 0)[0]\n",
        "  cost = 0.0\n",
        "\n",
        "  for i in incorrect_indices:\n",
        "\n",
        "    if (test_label[i]==0):\n",
        "      cost += 1.0\n",
        "    else:\n",
        "      cost += 100.0\n",
        "\n",
        "  return cost * (1/6916)\n"
      ],
      "metadata": {
        "id": "FYL9GC-CWKyH"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 1 (a) Logistic Regression**"
      ],
      "metadata": {
        "id": "VX-_Ol8W3DVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# helpful functions\n",
        "\n",
        "# X is the train data\n",
        "# w is the weight vector\n",
        "\n",
        "def sigmoid(X, w):\n",
        "  return 1/(1 + np.exp(-np.linalg.multi_dot([w,X.T])))\n",
        "\n",
        "# X is the array containing train data\n",
        "# C is the ground truth class label\n",
        "# w is the updated weight vector\n",
        "\n",
        "def loss_func(X,C, w):\n",
        "  Y = sigmoid(X, w)\n",
        "  cross_entropy_loss = - np.sum((C * np.log(Y) + (1-C)* np.log(1 - Y)))\n",
        "\n",
        "  return cross_entropy_loss"
      ],
      "metadata": {
        "id": "jQ6bDNfsOqNR"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining parameters\n",
        "\n",
        "max_iter = 1000\n",
        "\n",
        "#step_size\n",
        "eta = 0.001\n",
        "\n",
        "\n",
        "# X is train data\n",
        "# C is train labels\n",
        "\n",
        "def train(X,C):\n",
        "  \n",
        "  #initialize weight vector (w)\n",
        "  w = np.zeros([1,10])\n",
        "  X = np.append(X, np.ones([400,1]), axis = 1)\n",
        "  #w = np.random.normal(0, 1, size=(1, 9))\n",
        "\n",
        "  loss = []\n",
        "  for i in range(max_iter):\n",
        "    Y = sigmoid(X, w)\n",
        "    temp = Y - C\n",
        "    delta_E = np.linalg.multi_dot([temp, X])\n",
        "\n",
        "    w = w - eta * delta_E\n",
        "\n",
        "    loss.append(loss_func(X,C,w))\n",
        "\n",
        "    if ( abs(loss[i] - loss[i-1]) < 0.001 and i > 100 ):\n",
        "      break\n",
        "\n",
        "  return loss, w\n",
        "\n",
        "def predict(X, w):\n",
        "  X = np.append(X, np.ones([283,1]), axis = 1)\n",
        "  prediction = np.linalg.multi_dot([w,X.T]).squeeze()\n",
        "  C_hat = []\n",
        "\n",
        "  for p in prediction:\n",
        "    \n",
        "    if (p >=0):\n",
        "      C_hat.append(1)\n",
        "    else:\n",
        "      C_hat.append(0)\n",
        "    \n",
        "  return C_hat\n",
        "\n",
        "\n",
        "loss_ , w = train(train_data, train_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFoKU8QLPdRB",
        "outputId": "968b713f-0160-4079-a305-f1c3480cdc1f"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in log\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in multiply\n",
            "  app.launch_new_instance()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = range(0,len(loss_))\n",
        "y = loss_\n",
        "\n",
        "plt.plot(x, y, color='g')\n",
        "\n",
        "# naming the x axis\n",
        "plt.xlabel('i')\n",
        "# naming the y axis\n",
        "plt.ylabel(\"Loss at i'th iteration\")\n",
        " \n",
        "# giving a title to my graph\n",
        "plt.title('Loss function plot')\n",
        " \n",
        "# function to show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "mdLdeiq4lNo5",
        "outputId": "80c21043-480b-4ada-8079-13d316630267"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating MCR, RMS and Weighted Cost for Logistic Regression**"
      ],
      "metadata": {
        "id": "hiFY_RnmWJYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C_hat = predict(test_data, w)\n",
        "C_hat = np.array(C_hat)\n",
        "\n",
        "MCR_LR, comparison_LR = miss_classification_rate(C_hat)\n",
        "\n",
        "print(\"Number of miss classified instances: \", 283 - np.count_nonzero(comparison_LR))\n",
        "print()\n",
        "print(\"Miss Classified Rate: \", MCR_LR)\n",
        "print()\n",
        "\n",
        "# Calculating RMS\n",
        "\n",
        "prob_LR = sigmoid(np.append(test_data, np.ones([283,1]), axis = 1), w).squeeze()\n",
        "correct_classified_prob_LR = prob_LR[comparison_LR]\n",
        "\n",
        "RMS_LR = RMS_func(correct_classified_prob_LR)\n",
        "print(\"RMS margin for LR: \", RMS_LR)\n",
        "\n",
        "# \"\"\"*** Weighted Cost of Logistic Regression***\"\"\"\n",
        "print()\n",
        "weighted_cost_LR = weighted_cost(comparison_LR)\n",
        "\n",
        "print(\"***** Weighted Cost of LR *****\\n\")\n",
        "print(weighted_cost_LR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbJT5t-s9S1z",
        "outputId": "848308fc-5bdb-47e7-8a9c-d226d26ba25b"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of miss classified instances:  3\n",
            "\n",
            "Miss Classified Rate:  0.010600706713780883\n",
            "\n",
            "RMS margin for LR:  0.46687549965023\n",
            "\n",
            "***** Weighted Cost of LR *****\n",
            "\n",
            "0.01474840948525159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4eldU2Pk6IRf"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 1 (b) KNN classifier**"
      ],
      "metadata": {
        "id": "bQVbSTr-52Nb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "MCR_knn = []\n",
        "number_miss_clsf_KNN = []\n",
        "weighted_cost_KNN = []\n",
        "\n",
        "for k in range(10):\n",
        "    \n",
        "    classifier_knn = KNeighborsClassifier(n_neighbors=k+1)\n",
        "    classifier_knn.fit(train_data, train_label)\n",
        "\n",
        "    test_pred_knn = classifier_knn.predict(test_data)\n",
        "    mcr_ , comparison_KNN = miss_classification_rate(test_pred_knn)\n",
        "    MCR_knn.append(mcr_)\n",
        "\n",
        "    number_miss_clsf_KNN.append(283 - np.count_nonzero(comparison_KNN))\n",
        "\n",
        "    print(\"-----\", k+1 , \" Neighbours -----\")\n",
        "    print()\n",
        "    print(\"Number of miss classification : \", number_miss_clsf_KNN[k])\n",
        "    print(\"MCR : \", mcr_)\n",
        "\n",
        "\n",
        "    # \"\"\"*** Weighted Cost KNN***\"\"\"\n",
        "\n",
        "    weighted_cost_KNN.append(weighted_cost(comparison_KNN))\n",
        "\n",
        "    print(\"Weighted Cost : \", weighted_cost_KNN[k])\n",
        "    \n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = range(1,len(MCR_knn)+1)\n",
        "y = MCR_knn\n",
        "\n",
        "plt.plot(x, y, color='g')\n",
        "\n",
        "# naming the x axis\n",
        "plt.xlabel('k-NN')\n",
        "# naming the y axis\n",
        "plt.ylabel(\"MCR for kNN\")\n",
        " \n",
        "# giving a title to my graph\n",
        "plt.title('Miss Classification Rate plot')\n",
        " \n",
        "# function to show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iZ0T1ro650ik",
        "outputId": "d2c06682-3e88-4cea-eef4-d5f1b5c37c64"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- 1  Neighbours -----\n",
            "\n",
            "Number of miss classification :  5\n",
            "MCR :  0.017667844522968212\n",
            "Weighted Cost :  0.015037593984962405\n",
            "\n",
            "----- 2  Neighbours -----\n",
            "\n",
            "Number of miss classification :  8\n",
            "MCR :  0.028268551236749095\n",
            "Weighted Cost :  0.08704453441295545\n",
            "\n",
            "----- 3  Neighbours -----\n",
            "\n",
            "Number of miss classification :  4\n",
            "MCR :  0.014134275618374548\n",
            "Weighted Cost :  0.000578368999421631\n",
            "\n",
            "----- 4  Neighbours -----\n",
            "\n",
            "Number of miss classification :  5\n",
            "MCR :  0.017667844522968212\n",
            "Weighted Cost :  0.029352226720647773\n",
            "\n",
            "----- 5  Neighbours -----\n",
            "\n",
            "Number of miss classification :  5\n",
            "MCR :  0.017667844522968212\n",
            "Weighted Cost :  0.015037593984962405\n",
            "\n",
            "----- 6  Neighbours -----\n",
            "\n",
            "Number of miss classification :  3\n",
            "MCR :  0.010600706713780883\n",
            "Weighted Cost :  0.01474840948525159\n",
            "\n",
            "----- 7  Neighbours -----\n",
            "\n",
            "Number of miss classification :  4\n",
            "MCR :  0.014134275618374548\n",
            "Weighted Cost :  0.014893001735106997\n",
            "\n",
            "----- 8  Neighbours -----\n",
            "\n",
            "Number of miss classification :  3\n",
            "MCR :  0.010600706713780883\n",
            "Weighted Cost :  0.01474840948525159\n",
            "\n",
            "----- 9  Neighbours -----\n",
            "\n",
            "Number of miss classification :  3\n",
            "MCR :  0.010600706713780883\n",
            "Weighted Cost :  0.01474840948525159\n",
            "\n",
            "----- 10  Neighbours -----\n",
            "\n",
            "Number of miss classification :  3\n",
            "MCR :  0.010600706713780883\n",
            "Weighted Cost :  0.01474840948525159\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7qYqGLEpJHYQ"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 1 (c) LDA**"
      ],
      "metadata": {
        "id": "m5vdClgiC3af"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "\n",
        "MCR_LDA = []\n",
        "\n",
        "lda = LDA()\n",
        "lda.fit(train_data, train_label)\n",
        "test_pred_LDA = lda.predict(test_data)\n",
        "\n",
        "MCR_LDA, comparison_LDA = miss_classification_rate(test_pred_LDA)\n",
        "\n",
        "print(\"Number of Miss Classification using LDA: \", 283 - np.count_nonzero(comparison_LDA))\n",
        "print()\n",
        "print(\"Miss classification rate for LDA : \", MCR_LDA)\n",
        "\n",
        "\n",
        "# \"\"\"*** Weighted Cost LDA***\"\"\"\n",
        "print()\n",
        "weighted_cost_LDA = weighted_cost(comparison_LDA)\n",
        "\n",
        "print(\"***** Weighted Cost of LDA *****\\n\")\n",
        "print(weighted_cost_LDA)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFmzESUDDrX2",
        "outputId": "aad25390-adc5-457f-94e1-660d6e7367fc"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Miss Classification using LDA:  5\n",
            "\n",
            "Miss classification rate for LDA :  0.017667844522968212\n",
            "\n",
            "***** Weighted Cost of LDA *****\n",
            "\n",
            "0.0579814921920185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6g0OTGkVH6yb"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 1 (d) SVM**"
      ],
      "metadata": {
        "id": "SrDC-6D9ItGY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM 'linear' kernel**"
      ],
      "metadata": {
        "id": "yHwr4zCYAXqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "classifier_svm_lin = SVC(kernel='linear', probability=True)\n",
        "\n",
        "classifier_svm_lin.fit(train_data, train_label)\n",
        "\n",
        "test_pred_SVM_lin = classifier_svm_lin.predict(test_data)\n",
        "\n",
        "MCR_SVM_lin, comparison_SVM_lin = miss_classification_rate(test_pred_SVM_lin)\n",
        "\n",
        "print(\"Number of Miss Classification using SVM (linear kernel): \", 283 - np.count_nonzero(comparison_SVM_lin))\n",
        "print()\n",
        "print(\"Miss classification rate for SVM (linear kernel) : \", MCR_SVM_lin)\n",
        "\n",
        "\n",
        "# Calculating RMS\n",
        "\n",
        "test_pred_prob_SVM_lin = classifier_svm_lin.predict_proba(test_data)\n",
        "correct_classified_prob_SVM_lin = test_pred_prob_SVM_lin[:,1][comparison_SVM_lin]\n",
        "print()\n",
        "RMS_SVM_lin = RMS_func(correct_classified_prob_SVM_lin)\n",
        "print(\"RMS for SVM (linear kernel) : \", RMS_SVM_lin)\n",
        "\n",
        "\n",
        "# \"\"\"*** Weighted Cost SVM Linear Kernel***\"\"\"\n",
        "print()\n",
        "weighted_cost_SVM_lin = weighted_cost(comparison_SVM_lin)\n",
        "\n",
        "print(\"***** Weighted Cost of SVM Linear Kernel *****\\n\")\n",
        "print(weighted_cost_SVM_lin)"
      ],
      "metadata": {
        "id": "dTlymJyMJFwo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a2e1e87-cba1-4ffe-fa67-781b4e9252b0"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Miss Classification using SVM (linear kernel):  4\n",
            "\n",
            "Miss classification rate for SVM (linear kernel) :  0.014134275618374548\n",
            "\n",
            "RMS for SVM (linear kernel) :  0.4489134080884756\n",
            "\n",
            "***** Weighted Cost of SVM Linear Kernel *****\n",
            "\n",
            "0.014893001735106997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DLvvzaA7Phyf"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM 'poly' kernel**"
      ],
      "metadata": {
        "id": "PXAygTZZAB32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "classifier_SVM_poly = []\n",
        "test_pred_SVM_poly = []\n",
        "weighted_cost_SVM_poly = []\n",
        "MCR_SVM_poly = []\n",
        "RMS_SVM_poly = []\n",
        "\n",
        "classifier_SVM_poly.append(None)\n",
        "classifier_SVM_poly.append(None)\n",
        "\n",
        "test_pred_SVM_poly.append(None)\n",
        "test_pred_SVM_poly.append(None)\n",
        "\n",
        "for degree_ in range (2,6):\n",
        "\n",
        "  classifier_SVM_poly.append(SVC(kernel='poly', degree=degree_, probability=True))\n",
        "  classifier_SVM_poly[degree_].fit(train_data, train_label)\n",
        "  test_pred_SVM_poly.append(classifier_SVM_poly[degree_].predict(test_data))\n",
        "  \n",
        "  MCR_SVM_poly_, comparison_SVM_poly = miss_classification_rate(test_pred_SVM_lin)\n",
        "  MCR_SVM_poly.append(MCR_SVM_poly_)\n",
        "  \n",
        "  \n",
        "  print(\"-----Poly Kernel with Degree:\", degree_, \"-----\")\n",
        "  print()\n",
        "  print(\"Number of Miss Classification : \"  ,  283 - np.count_nonzero(comparison_SVM_poly))\n",
        "  print(\"Miss classification rate (MCR): \", MCR_SVM_poly)\n",
        "\n",
        "  test_pred_prob_SVM_poly = classifier_SVM_poly[degree_].predict_proba(test_data)\n",
        "  correct_classified_prob_SVM_poly = test_pred_prob_SVM_poly[:,1][comparison_SVM_poly]\n",
        "  RMS_SVM_poly.append(RMS_func(correct_classified_prob_SVM_poly))\n",
        "  print(\"RMS for SVM : \", RMS_SVM_poly[degree_-2])\n",
        "\n",
        "  # \"\"\"*** Weighted Cost SVM Poly Kernel***\"\"\"\n",
        "  print()\n",
        "\n",
        "  weighted_cost_SVM_poly.append(weighted_cost(comparison_SVM_poly))\n",
        "\n",
        "  print(\"***** Weighted Cost of SVM Poly Kernel *****\\n\")\n",
        "  print(weighted_cost_SVM_poly[degree_-2])\n",
        "  \n",
        "  print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybpe30cG4Xxg",
        "outputId": "d5476d4d-46c5-45a2-cc53-149a4d3f1254"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----Poly Kernel with Degree: 2 -----\n",
            "\n",
            "Number of Miss Classification :  4\n",
            "Miss classification rate (MCR):  [0.014134275618374548]\n",
            "RMS for SVM :  0.46445571191638607\n",
            "\n",
            "***** Weighted Cost of SVM Poly Kernel *****\n",
            "\n",
            "0.014893001735106997\n",
            "\n",
            "-----Poly Kernel with Degree: 3 -----\n",
            "\n",
            "Number of Miss Classification :  4\n",
            "Miss classification rate (MCR):  [0.014134275618374548, 0.014134275618374548]\n",
            "RMS for SVM :  0.44386200387870584\n",
            "\n",
            "***** Weighted Cost of SVM Poly Kernel *****\n",
            "\n",
            "0.014893001735106997\n",
            "\n",
            "-----Poly Kernel with Degree: 4 -----\n",
            "\n",
            "Number of Miss Classification :  4\n",
            "Miss classification rate (MCR):  [0.014134275618374548, 0.014134275618374548, 0.014134275618374548]\n",
            "RMS for SVM :  0.40184476704012206\n",
            "\n",
            "***** Weighted Cost of SVM Poly Kernel *****\n",
            "\n",
            "0.014893001735106997\n",
            "\n",
            "-----Poly Kernel with Degree: 5 -----\n",
            "\n",
            "Number of Miss Classification :  4\n",
            "Miss classification rate (MCR):  [0.014134275618374548, 0.014134275618374548, 0.014134275618374548, 0.014134275618374548]\n",
            "RMS for SVM :  0.3674036487154804\n",
            "\n",
            "***** Weighted Cost of SVM Poly Kernel *****\n",
            "\n",
            "0.014893001735106997\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM with 'rbf' kernel**"
      ],
      "metadata": {
        "id": "8Pc9rri7_9ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "classifier_svm_rbf = SVC(kernel='rbf', probability=True)\n",
        "\n",
        "classifier_svm_rbf.fit(train_data, train_label)\n",
        "\n",
        "test_pred_SVM_rbf = classifier_svm_rbf.predict(test_data)\n",
        "\n",
        "MCR_SVM_rbf, comparison_SVM_rbf = miss_classification_rate(test_pred_SVM_rbf)\n",
        "\n",
        "print(\"Number of Miss Classification of SVM (rbf kernel): \", 283 - np.count_nonzero(comparison_SVM_rbf))\n",
        "print()\n",
        "print(\"Miss classification rate (MCR) (rbf kernel) : \", MCR_SVM_rbf)\n",
        "\n",
        "# Calculating RMS\n",
        "\n",
        "test_pred_prob_SVM_rbf = classifier_svm_rbf.predict_proba(test_data)\n",
        "correct_classified_prob_SVM_rbf = test_pred_prob_SVM_rbf[:,1][comparison_SVM_rbf]\n",
        "print()\n",
        "RMS_SVM_rbf = RMS_func(correct_classified_prob_SVM_rbf)\n",
        "print(\"RMS for SVM (rbf kernel) : \", RMS_SVM_rbf)\n",
        "\n",
        "# \"\"\"*** Weighted Cost SVM RBF Kernel***\"\"\"\n",
        "print()\n",
        "weighted_cost_SVM_rbf = weighted_cost(comparison_SVM_rbf)\n",
        "\n",
        "print(\"***** Weighted Cost of SVM RBF Kernel *****\\n\")\n",
        "print(weighted_cost_SVM_rbf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSvfpAM24CPJ",
        "outputId": "9a84cfff-5771-4b51-8d21-612cc85f9310"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Miss Classification of SVM (rbf kernel):  5\n",
            "\n",
            "Miss classification rate (MCR) (rbf kernel) :  0.017667844522968212\n",
            "\n",
            "RMS for SVM (rbf kernel) :  0.4712341647261002\n",
            "\n",
            "***** Weighted Cost of SVM RBF Kernel *****\n",
            "\n",
            "0.015037593984962405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM with 'sigmoid' kernel**"
      ],
      "metadata": {
        "id": "Bz9bKJ9eBX59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "classifier_svm_sig = SVC(kernel='sigmoid', probability=True)\n",
        "\n",
        "classifier_svm_sig.fit(train_data, train_label)\n",
        "\n",
        "test_pred_SVM_sig = classifier_svm_rbf.predict(test_data)\n",
        "\n",
        "MCR_SVM_sig, comparison_SVM_sig = miss_classification_rate(test_pred_SVM_sig)\n",
        "\n",
        "print(\"Number of Miss Classification of SVM (sigmoid kernel): \", 283 - np.count_nonzero(comparison_SVM_sig))\n",
        "print()\n",
        "print(\"Miss classification rate (MCR) (sigmoid kernel) : \", MCR_SVM_sig)\n",
        "\n",
        "# Calculating RMS\n",
        "\n",
        "test_pred_prob_SVM_sig = classifier_svm_rbf.predict_proba(test_data)\n",
        "correct_classified_prob_SVM_sig = test_pred_prob_SVM_sig[:,1][comparison_SVM_sig]\n",
        "print()\n",
        "RMS_SVM_sig = RMS_func(correct_classified_prob_SVM_sig)\n",
        "print(\"RMS for SVM (sigmoid kernel) : \", RMS_SVM_sig)\n",
        "\n",
        "# \"\"\"*** Weighted Cost SVM Sigmoid Kernel***\"\"\"\n",
        "print()\n",
        "weighted_cost_SVM_sig = weighted_cost(comparison_SVM_sig)\n",
        "\n",
        "print(\"***** Weighted Cost of SVM Sigmoid Kernel *****\\n\")\n",
        "print(weighted_cost_SVM_sig)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5KmOna7A-GW",
        "outputId": "92071420-6a5a-49c7-f9db-1bdc28dc0b65"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Miss Classification of SVM (sigmoid kernel):  5\n",
            "\n",
            "Miss classification rate (MCR) (sigmoid kernel) :  0.017667844522968212\n",
            "\n",
            "RMS for SVM (sigmoid kernel) :  0.4712341647261002\n",
            "\n",
            "***** Weighted Cost of SVM Sigmoid Kernel *****\n",
            "\n",
            "0.015037593984962405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RMS Comparison between LR and SVM**"
      ],
      "metadata": {
        "id": "_XPSyjCzefGH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing the RMS margin of *part a* and *part d* we can see that the RMS margin of the SVM 'rbf' kernel is just a bit better than that of the others.\n",
        "\n",
        "Here we are calculating RMS margin which measures how confident is my classifier about the decision that it has made. So the higher the better.\n"
      ],
      "metadata": {
        "id": "RIEDZOERi6E8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"***RMS of Logistic Regression***\")\n",
        "print(RMS_LR)\n",
        "print()\n",
        "\n",
        "print(\"***RMS of SVM Linear Kernel***\")\n",
        "print(RMS_SVM_lin)\n",
        "print()\n",
        "\n",
        "print(\"***RMS of SVM Poly Kernel***\")\n",
        "print(RMS_SVM_poly)\n",
        "print()\n",
        "\n",
        "print(\"***RMS of SVM RBF Kernel***\")\n",
        "print(RMS_SVM_rbf)\n",
        "print()\n",
        "\n",
        "\n",
        "print(\"***RMS of SVM Sigmoid Kernel***\")\n",
        "print(RMS_SVM_sig)\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-NgXV2JZKcl",
        "outputId": "5d672707-0889-483e-d0bc-7efd35a64015"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***RMS of Logistic Regression***\n",
            "0.46687549965023\n",
            "\n",
            "***RMS of SVM Linear Kernel***\n",
            "0.4489134080884756\n",
            "\n",
            "***RMS of SVM Poly Kernel***\n",
            "[0.46445571191638607, 0.44386200387870584, 0.40184476704012206, 0.3674036487154804]\n",
            "\n",
            "***RMS of SVM RBF Kernel***\n",
            "0.4712341647261002\n",
            "\n",
            "***RMS of SVM Sigmoid Kernel***\n",
            "0.4712341647261002\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 1 (e) Decision Tree**"
      ],
      "metadata": {
        "id": "g5atfnJVYmov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn import tree\n",
        "from sklearn.datasets import load_iris\n",
        "import graphviz \n",
        "\n",
        "decision_tree = []\n",
        "MCR_DT = []\n",
        "weighted_cost_DT = []\n",
        "\n",
        "decision_tree.append(None)\n",
        "decision_tree.append(None)\n",
        "decision_tree.append(None)\n",
        "\n",
        "\n",
        "for max_depth_ in range(3,11):\n",
        "  decision_tree_ = tree.DecisionTreeClassifier(criterion='entropy', max_depth=max_depth_)\n",
        "  decision_tree_.fit(train_data, train_label)\n",
        "  decision_tree.append(decision_tree_)\n",
        "\n",
        "  test_pred_DT = decision_tree_.predict(test_data)\n",
        "\n",
        "  mcr_DT , comparison_DT = miss_classification_rate(test_pred_DT)\n",
        "  MCR_DT.append(mcr_DT)\n",
        "\n",
        "  print(\"-----DT with max depth\", max_depth_, \"-----\")\n",
        "  print()\n",
        "  print(\"Number of Miss Classification : \"  ,  283 - np.count_nonzero(comparison_DT))\n",
        "  print(\"Miss classification rate (MCR): \", mcr_DT)\n",
        "  print()\n",
        "\n",
        "  # \"\"\"*** Weighted Cost DT***\"\"\"\n",
        "  weighted_cost_DT.append(weighted_cost(comparison_LDA)) \n",
        "\n",
        "  print(\"***** Weighted Cost of DT *****\\n\")\n",
        "  print(weighted_cost_DT[max_depth_-3])\n",
        "  print()\n",
        "\n",
        "\n",
        "x = range(3,11)\n",
        "y = MCR_DT\n",
        "\n",
        "plt.plot(x, y, color='g')\n",
        "\n",
        "# naming the x axis\n",
        "plt.xlabel('Max Depth')\n",
        "# naming the y axis\n",
        "plt.ylabel(\"MCR for DT\")\n",
        " \n",
        "# giving a title to my graph\n",
        "plt.title('Miss Classification Rate plot')\n",
        " \n",
        "# function to show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "epQfLF5mDd9K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7c24fd5a-94a0-4f77-f900-cddc143fd7a9"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----DT with max depth 3 -----\n",
            "\n",
            "Number of Miss Classification :  10\n",
            "Miss classification rate (MCR):  0.035335689045936425\n",
            "\n",
            "***** Weighted Cost of DT *****\n",
            "\n",
            "0.0579814921920185\n",
            "\n",
            "-----DT with max depth 4 -----\n",
            "\n",
            "Number of Miss Classification :  7\n",
            "Miss classification rate (MCR):  0.02473498233215543\n",
            "\n",
            "***** Weighted Cost of DT *****\n",
            "\n",
            "0.0579814921920185\n",
            "\n",
            "-----DT with max depth 5 -----\n",
            "\n",
            "Number of Miss Classification :  8\n",
            "Miss classification rate (MCR):  0.028268551236749095\n",
            "\n",
            "***** Weighted Cost of DT *****\n",
            "\n",
            "0.0579814921920185\n",
            "\n",
            "-----DT with max depth 6 -----\n",
            "\n",
            "Number of Miss Classification :  9\n",
            "Miss classification rate (MCR):  0.03180212014134276\n",
            "\n",
            "***** Weighted Cost of DT *****\n",
            "\n",
            "0.0579814921920185\n",
            "\n",
            "-----DT with max depth 7 -----\n",
            "\n",
            "Number of Miss Classification :  12\n",
            "Miss classification rate (MCR):  0.04240282685512364\n",
            "\n",
            "***** Weighted Cost of DT *****\n",
            "\n",
            "0.0579814921920185\n",
            "\n",
            "-----DT with max depth 8 -----\n",
            "\n",
            "Number of Miss Classification :  12\n",
            "Miss classification rate (MCR):  0.04240282685512364\n",
            "\n",
            "***** Weighted Cost of DT *****\n",
            "\n",
            "0.0579814921920185\n",
            "\n",
            "-----DT with max depth 9 -----\n",
            "\n",
            "Number of Miss Classification :  10\n",
            "Miss classification rate (MCR):  0.035335689045936425\n",
            "\n",
            "***** Weighted Cost of DT *****\n",
            "\n",
            "0.0579814921920185\n",
            "\n",
            "-----DT with max depth 10 -----\n",
            "\n",
            "Number of Miss Classification :  14\n",
            "Miss classification rate (MCR):  0.04946996466431097\n",
            "\n",
            "***** Weighted Cost of DT *****\n",
            "\n",
            "0.0579814921920185\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3gU9fbH8fcJofcmSEdBJXQMRRGkiIJ6AaUooAKiWK941YsVhIC9oFxRQZMLWECKKDbgp1RFgUDoiDc0adJ7C0nO74+Z3BvjppFsZndzXs+zT3ZnZmc+u+KenZmd8xVVxRhjjMmqMK8DGGOMCS5WOIwxxmSLFQ5jjDHZYoXDGGNMtljhMMYYky1WOIwxxmSLFQ7jNyLyvogMy8PttRORXX5c/59ej4g8ICL7ROSkiJR3/17ih+1uEJF2ub3eQCYiE0VktNc5jG9WOEy2ich2EUkQkQpppseJiIpILQBVvV9VR+XytluIyLciclREDovIchEZmJvbSE/q1yMiBYE3getVtYSqHnL/bs3JNnx9YKpqfVVdmJP1prOthSJy1i14B0XkcxG5OIvP9WuRzg7331wdr3PkJ1Y4zIXaBvRJeSAiDYFi/tygiFwFzAcWAXWA8sADQBd/bjcdlYAiwAYPtp2bHlbVEjjvZwngdY/zmCBghcNcqI+Au1I97g9MTr1A6m/PIlJBRL5OtaewRETC3HlPishuETkhIptFpGM623wNmKSqr6jqQXWsVNXevhYWkadEZIu73o0ickuqeXVEZJGIHHO/bX/mThcRGSMi+0XkuIisE5EGqV+PiFwGbHZXdVRE5rvz//vNV0SKisgbIrLD3caPIlLUnTddRP5wpy8Wkfru9MFAP2CouxfwlTt9u4hc594vLCJvicge9/aWiBR257UTkV0i8ribf29W98ZU9SjwBdAk1Xs0UEQ2ue/fVhG5z51eHPgOqOLmPCkiVUQkLNV7fkhEpolIuXT+26RkfcZ9/7eLSL/08onIvSIS7/7bmS0iVdzpi91F1rg5bsvK6zU5Y4XDXKhfgFIiUk9ECgC3Ax9nsPzjwC6gIs639WcAFZHLgYeB5qpaErgB2J72ySJSDLgKmJGNjFuANkBpYCTwcapDMaOAeUBZoBrwL3f69UBb4DL3eb2BQ6lXqqq/AfXdh2VUtYOPbb8OXAlcDZQDhgLJ7rzvgLrARcAq4BN3vRPc+6+6h73+5mO9zwKtcD7gGwMtgOdSza/s5q4KDALGiUhZn+9OKiJSHrgViE81eT9wM1AKGAiMEZFmqnoKZy9vj5uzhKruAf4OdAeuBaoAR4BxGWy2MlDBzdofmOD+e0ibrQPwEs5/i4uBHcBUAFVt6y7W2M3xWWav1eScFQ6TEyl7HZ2ATcDuDJY9j/M/fU1VPa+qS9RplJYEFAYiRKSgqm5X1S0+nl8W59/r3qyGU9XpqrpHVZPdD5T/4HzQpuSpCVRR1bOq+mOq6SWBKwBR1U2qmuVtArh7UncDQ1R1t6omqepSVT3n5opR1RPu4xFAYxEpncXV9wOiVHW/qh7AKYh3ppp/3p1/XlW/BU4Cf/kwTmWsiBwDDuJ8iP89ZYaqfqOqW9w9u0U4hbZNBuu6H3hWVXelem09RSQ8g+cMU9Vz7vq/wSkOvl5zjKquctf7NHCVuOfSTN6zwmFy4iOgLzCANIepfHgN59vsPPewx1MAqhoPPIrzIbNfRKamHIZI4wjON/YsnbwFEJG7RGS1e3jsKNAA58MRnD0AAZaL86ulu90884F3cL4p7xeRCSJSKqvbdFXAOf/xlwIoIgVE5GX3cM5x/rd3VSHtsumogvONO8UOd1qKQ6qamOrxaZxzF+l5RFVLA434395XStYuIvKLe3joKHBjJjlrArNSvd+bcL4YVEpn+SPu3kt6ryXFn16zqp7E2QusmkEW40dWOMwFU9UdOCfJbwQ+z2TZE6r6uKpeAnQFHks5l6Gqn6rqNTgfPAq84uP5p4GfgR5ZySYiNYEPcA6DlVfVMsB6nGKBqv6hqveqahXgPuDdlPMTqjpWVa8EInAOWf0zK9tM5SBwFrjUx7y+QDfgOpxDSrVSIrt/M2tXvQfnfUpRw52WI6q6DhiNc2hL3PMmM3EOuVVy379vM8m5E+iiqmVS3Yqoanp7omXd8yWZvZY/vWb3OeXJeA/X+JEVDpNTg4AOab45/oWI3CzOCWkBjuF8E00WkctFpIP7QXUWOMP/zgWkNRQYICL/dI/JIyKNRWSqj2WL43y4HXCXG4izx5GSp5eIpHy7PuIumywizUWkpTg/tz3lZkovj0+qmgzEAG+6J40LiMhV7mssCZzD+cZcDHgxzdP3ARldCzIFeE5EKorzc+jhZHxuKTsm4ewddAUK4RxCPAAkikgXnPM/qXOWT3OI7X3gBbdo42bslsk2R4pIIRFpg3M+ZbqPZaYAA0WkifsevggsU9XtqbLk+vUzJn1WOEyOuMfAY7OwaF3ge5xj7j8D76rqApwPp5dxvqX/gXPC+Ol0trUU6ODetorIYWACzjfhtMtuBN5wt7UPaAj8lGqR5sAyETkJzMY5H7EV50TwBzjFZAfOB/xrWXh9aT0BrANWAIdx9qLCcA7p7cD5trwR50cGqUXjnO85KiJf+FjvaCAWWOuuf5U7LcdUNQF4G+e8wwngEWAaznvRF+d9Sln2V5wP9K1u1iruc2fjHI484b62lhls8g933XtwfhRwv7vetLm+B4bh7AHtxdmTuz3VIiOASW4On7+wM7lLbCAnY0xeE+dK+I9VtVpmy5rAY3scxhhjssUKhzHGmGyxQ1XGGGOyxfY4jDHGZEtGV3SGjAoVKmitWrW8jmGMMUFl5cqVB1W1Ytrp+aJw1KpVi9jYrPxi1BhjTAoR2eFruh2qMsYYky1+LRwi0lmcNtnxKb2J0swvLCKfufOXpTQtE5FaInLG7TO0WkTeT/WcK8VpdR0vImPdK5GNMcbkEb8VDrfV9jic9ssRQB8RiUiz2CCcRmd1gDH8uUfRFlVt4t7uTzX9PeBenCuR6wKd/fUajDHG/JU/9zhaAPGqutVtZTAVp7lbat1w+uOAM85Cx4z2INyxFEqp6i9uS+7JOP3/jTHG5BF/Fo6qON0yU+zir22Q/7uM2wr6GE7XS4Da4oxhvchtgJayfOpxjn2tE3BGUxORWBGJPXDgQM5eiTHGmP8K1JPje4EaqtoUeAz4NLtjIqjqBFWNVNXIihX/8msyY4wxF8ifhWM3UD3V42r8tX/+f5dxRwkrjTMQzTlVPQSgqitxBsS5zF0+dVM0X+s0xhjjR/4sHCuAuiJSW0QK4bRBnp1mmdk4Yw0D9ATmq6q6ffwLAIjIJTgnwbe6Q3geF5FW7rmQu4Av/fgajDEmKK3YvYIXFr/A8XPHc33dfisc7jmLh4G5OENITlPVDSISJSJd3cWicQaDicc5JJXyk922wFoRWY1z0vx+VT3sznsQ+BBnGNItwHf+eg3GGBOsxq0Yxys/vUIB5zt4rsoXTQ4jIyPVrhw3xuQXx88d5+I3LuaOhncw/m/jL3g9IrJSVSPTTg/Uk+PGGGMu0GfrP+P0+dPc3fRuv6zfCocxxoSYmNUx1K9YnxZVW/hl/VY4jDEmhGw8sJFfdv3C3U3vxl8dmaxwGGNMCImJiyE8LJw7G93pt21Y4TDGmBCRkJTA5DWT6Xp5VyoW99+Fz1Y4jDEmRHzz2zccOH2AQU0H+XU7VjiMMSZERMdFU6VkFa6/9Hq/bscKhzHGhIDdx3fzXfx3DGg8gPAw/w7uaoXDGGNCwOQ1k0nWZAY2Hej3bVnhMMaYIKeqxKyO4dqa11KnXB2/b88KhzHGBLklvy8h/nC8364UT8sKhzHGBLnouGhKFS5Fz4ieebI9KxzGGBPEjp87zvQN0+nToA/FChbLk21a4TDGmCA2df1UziSeybPDVGCFwxhjglpMXAwNLmpA8yrN82ybVjiMMSZIbdi/gWW7l3F3E/81NPTFCocxxgSpmLgYCoYV5I5Gd+Tpdq1wGGNMEEpISmDyWv83NPTFCocxxgShr3/7moOnD/q9oaEvVjiMMSYIRcdFU7VkVb83NPTFCocxxgSZ3cd3Myd+DgOaDKBAWIE8374VDmOMCTKT1kxyGho28X9DQ1+scBhjTBBJ1mRi4mJoV6sdl5a71JMMVjiMMSaILNmxhC1HtnhyUjyFFQ5jjAkiKQ0Nb613q2cZrHAYY0yQOHb2GDM2zqBvg7551tDQFyscxhgTJLxoaOiLFQ5jjAkSMatjaHhRQyKrRHqawwqHMcYEgfX717N893Lubpq3DQ19scJhjDFBwKuGhr5Y4TDGmACXkJTAR2s/otsV3ahQrILXcfxbOESks4hsFpF4EXnKx/zCIvKZO3+ZiNRKM7+GiJwUkSdSTdsuIutEZLWIxPozvzHGBIKvNn/lWUNDX/xWOESkADAO6AJEAH1EJCLNYoOAI6paBxgDvJJm/pvAdz5W315Vm6iqt2eIjDEmD0THRVOtVDU6XdLJ6yiAf/c4WgDxqrpVVROAqUC3NMt0Aya592cAHcU96yMi3YFtwAY/ZjTGmIC26/gu5m6Zy4DG3jQ09MWfhaMqsDPV413uNJ/LqGoicAwoLyIlgCeBkT7Wq8A8EVkpIoPT27iIDBaRWBGJPXDgQA5ehjHGeGfSarehYVNvGhr6Eqgnx0cAY1T1pI9516hqM5xDYA+JSFtfK1DVCaoaqaqRFSvm7ehYxhiTG5I1mZjVMbSv1Z5Lyl7idZz/8mfh2A1UT/W4mjvN5zIiEg6UBg4BLYFXRWQ78CjwjIg8DKCqu92/+4FZOIfEjDEm5CzesZitR7YGzEnxFP4sHCuAuiJSW0QKAbcDs9MsMxvo797vCcxXRxtVraWqtYC3gBdV9R0RKS4iJQFEpDhwPbDej6/BGGM8Ex0XTenCpT1taOhLuL9WrKqJ7l7CXKAAEKOqG0QkCohV1dlANPCRiMQDh3GKS0YqAbPc8+fhwKeqOsdfr8EYY7yS0tBwYJOBFC1Y1Os4f+K3wgGgqt8C36aZNjzV/bNAr0zWMSLV/a1A49xNaYwxgWfK+imcTTzreUNDXwL15LgxxuRrMXExNKrUiCsvvtLrKH9hhcMYYwLMun3rWLFnBXc38b6hoS9WOIwxJsDExMVQqEChgGho6IsVDmOMCSDnEs85DQ0v70b5YuW9juOTFQ5jjAkgszfP5tCZQwF37UZqVjiMMSaAxKyOoXqp6lx3yXVeR0mXFQ5jjAkQO4/tZG78XAY0CZyGhr5Y4TDGmAAxac0kFGVgk8BpaOiLFQ5jjAkAyZpMTFwMHWp3oHbZ2l7HyZAVDmOMCQCLti9i29FtAX1SPIUVDmOMCQApDQ1vueIWr6NkygqHMcZ47OjZo8zcNJN+DfsFXENDX6xwGGOMx6asC9yGhr74tTuuMSbvJWsy55POex0jy8LDwgP6p6d5IWZ1DI0rNabZxc28jpIlVjiMCSEJSQk0Hd+UjQc2eh0lyyqXqMzC/gu5vMLlXkfxxNp9a4ndE8vbnd8OyIaGvljhMCaExMTFsPHARh5t+SgXFb/I6ziZUpQxv4yh5/Se/DLoF4oXKu51pDyX0tCwX8N+XkfJMiscxoSIs4lnGb14NFdXv5o3b3gzaL69Nq/SnBs+voEHvnmASd0nBU3u3JDS0LD7Fd0DtqGhL3Zy3JgQMT52PLtP7GZ0+9FB9eHb6dJOjGw3ko/WfsSElRO8jpOnvtz8JYfPHA6KazdSs8JhTAg4lXCKl358ifa12tO+dnuv42Tbs22fpUudLjwy5xFi98R6HSfPxMTFUKN0DTrW7uh1lGyxwmFMCBi3Yhz7Tu1jVPtRXke5IGESxke3fETlEpXpOa0nh04f8jqS3/1+7HfmbZnHgMaB3dDQFyscxgS5E+dO8OpPr9K5Tmda12jtdZwLVr5YeWb0msHek3u5c9adJGuy15H8atJqt6Fh08BuaOiLFQ5jgtzby97m0JlDRLWL8jpKjjWv2py3bniL7+K/48UlL3odx2+SNZmY1TF0rN2RWmVqeR0n26xwGBPEjpw5wutLX6fr5V1pXrW513Fyxf2R99OvYT+GLxjO91u/9zqOXyzcvpDtR7cH3UnxFFY4jAlib/78JsfOHQuJvY0UIsL4m8cTUTGCPjP7sOv4Lq8j5brouGjKFClD9yu6ex3lgljhMCZIHTx9kLeWvUWviF40rtzY6zi5qnih4szsPZOziWfpPb03CUkJXkfKNUfOHGHmxuBpaOiLFQ5jgtSrP73K6fOnGdlupNdR/OLyCpcT0zWGn3f9zND/G+p1nFwzZf0UziWdC5qGhr5Y4TAmCP1x8g/eWf4OfRv2pV7Fel7H8Zte9XsxpOUQ3l72NtM2TPM6Tq6IiYuhSeUmQdPQ0BcrHMYEoZeWvERCUgLPX/u811H87tVOr3JVtasYNHsQvx781es4ObLmjzWs3LuSu5sE794GWOEwJujsOr6L91e+z4AmA6hTro7XcfyuUIFCTOs1jaLhRekxrQcnE056HemCRcdFU7hAYfo1Cp6Ghr5Y4TAmyLyw+AVUlWFth3kdJc9UK1WNKT2m8OvBX7nv6/tQVa8jZdvZxLN8vPZjbql3C+WKlvM6To6kWzhEpEZeBjHGZG7bkW18GPch9za7l5planodJ091vKQjUe2i+HTdp7wX+57XcbLty1+/5MjZI0F/mAoy3uP4IqcrF5HOIrJZROJF5Ckf8wuLyGfu/GUiUivN/BoiclJEnsjqOo0JZaMWj6KAFOCZNs94HcUTT7d5mpvq3sSjcx5l+e7lXsfJlpjVbkPDS4KroaEvGRWOHPVlFpECwDigCxAB9BGRiDSLDQKOqGodYAzwSpr5bwLfZXOdxoSk3w79xqQ1k3gg8gGqlqrqdRxPhEkYk2+ZTNVSVek1vVfQNEPccXQH/7fl/xjYZCBhEvxnCDIayKmqiIxNb6aqPpLJulsA8aq6FUBEpgLdgNRjWnYDRrj3ZwDviIioqopId2AbcCqb6zQmJI1cNJIi4UV46pr8vaNdrmg5pveaTuuY1twx6w6+6ftNwH8YT1ozCYCBTYKvoaEvGb3bZ4CVGdwyUxXYmerxLneaz2VUNRE4BpQXkRLAk0DaK5uysk4ARGSwiMSKSOyBAweyENeYwLVh/wamrJvC31v8nUolKnkdx3ORVSIZ23ksc+LnMHrxaK/jZChZk/n36n/T8ZKOIXNeKqM9jkOqOinPkvzZCGCMqp680JHMVHUCMAEgMjIy+H6CYUwqzy98nhKFSvDPq//pdZSAMfjKwfy08ydGLBxBq2qtuP7S672O5NOCbQvYfnQ7L3V8yesouSajPY6cNofZDVRP9biaO83nMiISDpQGDgEtgVdFZDvwKPCMiDycxXUaE1Li9sYxc9NM/tHqH0E1LrW/iQjv3/w+9S+qT9+Zfdl5bGfmT/JAdFw0ZYuUDdqGhr6kWzhUtZWIhIvI30Tkn+7tZvcDPitWAHVFpLaIFAJuB2anWWY20N+93xOYr442qlpLVWsBbwEvquo7WVynMSFl+MLhlClShn9c9Q+vowScYgWLMbP3TBKSEug1vVfANUM8cuYIn2/6nH4N+1EkvIjXcXJNRtdxVAU2AI8DVXDOJfwT2CAiVTJbsXvO4mFgLrAJmKaqG0QkSkS6uotF45zTiAceAzI865feOjPLYkywWrZrGV//9jX/vPqflClSxus4Aemy8pcR0y2GZbuX8fjcx72O8yefrvs06Bsa+iLpXYEpIhOB1ar6VprpjwBXqmp/n08MQJGRkRobG+t1DGOy7YaPb2DV3lVsG7KNEoVKeB0noD029zHG/DKGKT2mcHuD272OA8CVE65EVVl13yqvo1wQEVmpqpFpp2d0jqNV2qIBoKpjgVa5Gc4Y81dLdixh3pZ5PNn6SSsaWfDKda/Qunpr7pl9DxsPeP8L/dV/rGbV3lUht7cBmf8cNz2nczuIMeZ/VJVhC4ZRuURlHmz+oNdxgkLBAgWZ1msaxQsVp+e0np43Q4xe5TY0bBjcDQ19yehEd2kRudXHdAFK+SmPMQaYv20+i3YsYmznsRQrWMzrOEGjSskqTO0xles+uo57v7qXT2/9lAv9SX9OnE08yyfrPuHWerdStmjZPN++v2VUOBYBf0tn3mI/ZDHG4OxtPLfgOaqXqs7gKwd7HSfotK/dntHtR/PM/GdoXb01D7d4OM8zfPHrF05DwxA8TAUZFA5VDY1r440JMt/Ff8cvu35h/M3jKRxe2Os4QenJa55k6a6lPDb3MSKrRNKqWt6elo2Ji6Fm6Zp0qN0hT7ebVwK7wYsx+UzKuY3aZWqHTF8jL4RJGJO7T6ZaqWr0nt6bg6cP5tm2dxzdwfdbvw+Zhoa+hOarMiZIffHrF6zau4rnr32eggUKeh0nqJUtWpYZvWew/9R++n3ej6TkpDzZ7sTVEwEY0GRAnmzPCxkWDhEJE5Gr8yqMMflZsiYzfOFwLit/WdAPLRooml3cjH91+RfztswjalGU37eX0tDwukuuC5mGhr5kWDhUNRln/AtjjJ9N2zCN9fvXM7LdSMLDstrZx2Tmnmb30L9xf0YtHsWc+Dl+3db8bfPZcWwHg5oO8ut2vJaVQ1U/iEgP8eI3bcbkE4nJiYxYOIIGFzWgd/3eXscJKSLCuze9S8NKDen3eT92HN3ht22lNDTsdkU3v20jEGSlcNwHTAcSROS4iJwQkeN+zmVMvvLJ2k/YfGgzI9uNDNkTql4qVrAYM3rNIDE5kV7Te3Eu8Vyub+PwmcPM2jSLOxrdEVINDX3J9F+oqpZU1TBVLaiqpdzHdgGgMbnkfNJ5ohZH0bRyU2654hav44SsuuXrMrHbRFbsWcFjcx/L9fWHakNDX7J0INXtZtvWfbhQVb/2XyRj8peJqyey9chWvu7ztSdXOecnt9S7hSeueoLXf36d1jVa07dh31xbd0xcDM0ubkaTyk1ybZ2BKtM9DhF5GRiCM673RmCIiITOUFbGeOhc4jlGLR5Fy6otubHujV7HyRdeuu4l2tRow71f3cuG/bkzKkPc3jji/ogL+ZPiKbJyMPVGoJOqxqhqDNAZuMm/sYzJHz5Y9QE7j+9kdIfRtreRR8LDwvms52eULFSSHtN6cOLciRyvMzrOaWjYp0GfXEgY+LJ6Fi71CDKl/RHEmPzm9PnTvLDkBdrWbEvH2h29jpOvXFzyYqb2nMp/Dv+He766h/TGJcqKlIaGPSJ6hGRDQ1+yUjheAuJEZKKITAJWAi/4N5Yxoe+9Fe/xx8k/GNV+lO1teKBdrXa82OFFpm2Yxr+W/+uC1zNr0yyOnj3K3U1C/6R4ioxGAGytqj+JSGGgHNDcnbVcVf/Iq4C5wUYANIHmZMJJar9dm6aVmzLvznlex8m3VJXun3Xn2/98y6IBi7i6evYbZXT6qBPxh+PZ8siWkPsp9YWMADjW/fuzqu5V1dnuLaiKhjGBaOyysRw8fZBR7Ud5HSVfExEmdZ9EjdI16D29N/tP7c/W87cf3R7yDQ19yeiVnheRCUA1ERmb9pZXAY0JNcfOHuP1pa9z82U307JaS6/j5HtlipRhRq8ZHDx9kL4z+2arGeLE1RMRJKQbGvqSUeG4GZiPM4TsSh83Y8wFGPPLGI6cPUJUO/833TNZ0/Tipoy7cRw/bPuBEQtHZOk5SclJ/Hv1v+l0aSdqlK7h34ABJqOBnA4CU0Vkk6quycNMxoSsQ6cP8ebPb9KjXg+aXtzU6zgmlUHNBvHTzp8YvWQ0V1W/KtPrauZvm8/vx37ntU6v5VHCwJGVliNWNIzJJa8vfZ2TCScZ2W6k11GMD+NuHEfjSo254/M72H50e4bLRsdFU65oObpdHtoNDX3JP2dzjPHY/lP7Gbt8LLc3uJ36F9X3Oo7xoWjBoszoPYNkTc6wGeLhM4eZ9ess7mh4R74c3tcKhzF55OUfX+Zs4llGtBvhdRSTgTrl6jCp+yRi98Ty6JxHfS7zydpPSEhKyBcNDX3JbATAAiJSIdXjQiIyWEQ2+T+aMaFj9/HdvBf7Hnc1vovLyl/mdRyTiW5XdGPo1UN5f+X7fLz24z/NU1Wi46K58uIraVy5sUcJvZVu4RCR24HDwFoRWSQi1wNbgS6AjWtpTDa8uORFEpMTGd52uNdRTBa90PEFrq15LYO/Gsy6fev+Oz3ujzjW7FuTbxoa+pLRHsdzwJWqWgX4B/AV8ICq3qKqq/IknTEhYMfRHXyw6gMGNR1E7bK1vY5jsig8LJypPadSukhpekzrwfFzzvh10auiKRJehD4N80dDQ18yKhwJqhoP4BaK/6jqV3kTy5jQMXqx0/n22TbPeh3FZFPlEpX5rOdnbD2ylbu/vJsz58/w6fpP6VGvB2WKlMl8BSEqo4GcLhKR1MNklUn9WFXf9F8sY0JD/OF4/r363zzU/CGql67udRxzAdrWbMtLHV9i6PdDOXbumNPQMJ+eFE+RUeH4ACiZweOQlpScxLgV46hQrEKujhJm8peoRVEUKlCIp9s87XUUkwNPXP0ES3ct5Ytfv6B2mdq0q9XO60ieyujK8RxfoSQinYG3gQLAh6r6cpr5hYHJwJXAIeA2Vd0uIi2ACSmLASNUdZb7nO3ACSAJSPTVuTE3hEkYU9dPZefxndxa79aQH3ze5L5NBzbx8dqPefyqx6lcorLXcUwOiAgTu02k65muDGg8IF81NPQlo19VvSYi9/mYfp87nGyGRKQAMA7nV1gRQB8RiUiz2CDgiKrWAcYAr7jT1wORqtoEZ8TB8SKSusi1V9Um/ioabn5GdxjNruO7+GDlB/7ajAlhIxaNoHih4gxtPdTrKCYXlC5SmkUDFjGw6UCvo3guo7LZgf9960/tA5wGiJlpAcSr6lZVTQCmAmmvze8GTHLvzwA6ioio6mlVTXSnFwEufHiuHOhQuwPtarXjhSUvcPr8aS8imCC1dt9apm2YxpCWQ6hYvKLXcYzJVRkVjsLqY5QnVU3GOXyUmarAzlSPd7nTfC7jFopjQHkAEWkpIhuAdcD9qQqJAvNEZKWIDE5v4+6FirEiEnvgwIEsxPVtVPtR7Du1jwAKDpYAABolSURBVHdXvHvB6zD5z/AFwylduDSPX/W411GMyXUZFY4zIlI37UR32hn/RXKo6jJVrY8z8uDTIpJykuEaVW2GcwjsIRFpm87zJ6hqpKpGVqx44d/4rqlxDTdcegOv/PRKrgxqb0Jf7J5Yvtz8JY9f9Xi+GYPa5C8ZFY7hwHciMkBEGrq3gcA37rzM7AZS//6wmjvN5zLuOYzSOCfJ/0tVNwEngQbu493u3/3ALJxDYn4V1T6Kg6cPMnaZjV9lMjd8wXDKFS3HkFZDvI5ijF+kWzhU9TugO9AemOje2gM9VPXbLKx7BVBXRGqLSCHgdmB2mmVmA/3d+z2B+aqq7nPCAUSkJnAFsF1EiotISXd6ceB6nBPpftWiagu6Xt6V139+naNnj/p7cyaILd25lO/iv+PJ1k9SqnApr+MY4xcZ/qZMVderan9VvdK93aWq6zJ6TqrnJgIPA3OBTcA0Vd0gIlEi0tVdLBooLyLxwGPAU+70a4A1IrIaZ6/iQXdgqUrAjyKyBlgOfKOqc7L3ki9MVLsojp49yps/23WPJn3DFgzjouIX8VDzh7yOYozfiI/z384MkbR7B3+iql0zmh9IIiMjNTY2Nsfr6TW9F3Pj57JtyDbKFyufC8lMKFmwbQEdJnfgrRvessNUJiSIyEpflz1kdOX4VTi/eJoCLCNrv6QKaSPbjWTmxpm8tvQ1Xr4u00tZTD6iqgxbMIyqJatyX+RfLn8yJqRkdKiqMvAMzknpt4FOwEFVXaSqi/IiXKCJqBhB34Z9+dfyf7Hv5D6v45gAMm/LPH7a+RPPtnnWugyYkJfRyfEkVZ2jqv2BVkA8sFBEHs6zdAHo+Wuf51ziOV7+0fY4jENVeW7Bc9QsXZNBzfLvGA0m/8hsBMDCInIr8DHwEDAW52R1vlW3fF36N+7Pe7Hvsev4Lq/jmADw1W9fEbsnluHXDqdQgUJexzHG7zLqVTUZ+BloBoxU1eaqOirlOor8bNi1w0jWZF5c8qLXUYzHkjWZYQuGUadcHe5qfJfXcYzJExntcdwB1AWGAEtF5Lh7OyEix/MmXmCqVaYW9zS7hw9Xfcj2o9u9jmM8NHPjTNbuW8uIa0cQHpbRb02MCR0ZneMIU9WS7q1UqltJVc33VzY92+ZZwiSMUYtGeR3FeCQpOYnnFz5PRMUIbm9wu9dxjMkz+bupfA5ULVWV+yPvZ9KaScQfjvc6jvHAlPVT2HRwEyPbjaRAWAGv4xiTZ6xw5MBT1zxF4fDCjFyU4zGvTJBJTE5k5KKRNK7UmFvr3ep1HGPylBWOHKhcojIPN3+YT9Z+wsYDG72OY/LQ5DWTiT8cT1T7qHw/GpzJf+xffA4NbT2UEoVKMGLhCK+jmDySkJRA1KIomldpzt8u+5vXcYzJc1Y4cqh8sfI82upRpm+czuo/Vnsdx+SB6FXR7Di2g1HtRyGS7zvxmHzICkcueOyqxyhTpAzPL3ze6yjGz86cP8PoJaO5psY1XH/p9V7HMcYTVjhyQZkiZXjiqieYvXk2K3av8DqO8aPxK8ez58Qe29sw+ZoVjlzySMtHKF+0PMMWDPM6ivGTUwmneOnHl+hQuwPtarXzOo4xnrHCkUtKFi7JU9c8xdwtc/nx9x+9jmP84J3l77D/1H5GtbeLPk3+ZoUjFz3Y/EEql6hsex0h6Pi547y69FW61OnC1dWv9jqOMZ6ywpGLihUsxtPXPM3C7QuZv22+13FMLnrrl7c4fOYwUe2jvI5ijOescOSywVcOplqpagxbMIz0huU1weXwmcO8+fObdL+iO5FV/jKKpjH5jhWOXFYkvAjPtXmOpTuXMid+jtdxTA4t2LaA5h8052TCSUa2s9YyxoAVDr8Y2HQgtcrUsr2OIHbs7DEGfzWYDpM7ECZh/HDXDzSq1MjrWMYEBCscflCoQCGev/Z5Vu5dyZebv/Q6jsmmrzZ/RcS7EUTHRTP06qGsvX8t19a61utYxgQMKxx+ckejO7is/GUMXzCcZE32Oo7Jgv2n9tNnZh+6Tu1K+aLlWXbPMl7p9ApFCxb1OpoxAcUKh5+Eh4Uz4toRrNu/jhkbZ3gdx2RAVflk7SdEjIvg802fM6r9KGIHx9qJcGPSYYXDj25rcBv1K9bn+YXPk5Sc5HUc48POYzv525S/ccesO6hbvi5x98XxXNvnKFSgkNfRjAlYVjj8KEzCGNluJL8e/JVP133qdRyTSrIm837s+9R/tz4Lti/grRve4seBPxJRMcLraMYEPCscfnZLvVtoWrkpIxaN4HzSea/jGOA/h/5Dh0kdeOCbB2hZrSXrH1jPkFZDbPhXY7LICoefhUkYUe2j2HpkK5PWTPI6Tr6WmJzIaz+9RqP3G7H6j9VEd41m3h3zqF22ttfRjAkqVjjywE11b6Jl1ZaMWjyKc4nnvI6TL635Yw2tPmzF0O+H0rlOZzY+tJG7m95trdGNuQBWOPKAiDCq/Sh+P/Y7H6760Os4+cq5xHMMmz+MyA8i2Xl8J9N6TuPz3p9TpWQVr6MZE7SscOSR6y65jjY12vDCkhc4c/6M13HyhZ93/kzT8U0ZvWQ0fRv2ZeODG+lVv5ftZRiTQ34tHCLSWUQ2i0i8iDzlY35hEfnMnb9MRGq501uIyGr3tkZEbsnqOgOViDC6w2j2ntzLe7HveR0npJ1KOMWjcx6ldUxrTiac5Nu+3zKp+yTKFyvvdTRjQoLfCoeIFADGAV2ACKCPiKT9reMg4Iiq1gHGAK+409cDkaraBOgMjBeR8CyuM2C1rdmW6y65jpd/fJmTCSe9jhOSvt/6PQ3ea8Dby97mweYPsuHBDXSp28XrWMaEFH/ucbQA4lV1q6omAFOBbmmW6Qak/NRoBtBRRERVT6tqoju9CJDSKTAr6wxoo9qP4sDpA7yz/B2vo4SUI2eOMOjLQXT6qBOFChRi8YDFvHPjO5QsXNLraMaEHH8WjqrAzlSPd7nTfC7jFopjQHkAEWkpIhuAdcD97vysrBP3+YNFJFZEYg8cOJALLyd3tKrWipvq3sSrP73KsbPHvI4TEmZtmkXEuxFMWjOJp1o/xZr719CmZhuvYxkTsgL25LiqLlPV+kBz4GkRKZLN509Q1UhVjaxYsaJ/Ql6gqPZRHDl7hLd+ecvrKEFt38l99J7em1un3UrlEpVZfu9yXrruJYqEZ+ufijEmm/xZOHYD1VM9ruZO87mMiIQDpYFDqRdQ1U3ASaBBFtcZ8Jpd3Ixb693Km7+8yeEzh72OE3RUlclrJlNvXD2+3PwlL3R4geX3LKfZxc28jmZMvuDPwrECqCsitUWkEHA7MDvNMrOB/u79nsB8VVX3OeEAIlITuALYnsV1BoWR7UZy4twJXl/6utdRgsrvx37nxk9vpP8X/alXsR5r7l/DM22eoWCBgl5HMybf8FvhcM9JPAzMBTYB01R1g4hEiUhXd7FooLyIxAOPASk/r70GWCMiq4FZwIOqejC9dfrrNfhTg4sacFuD2xi7bCz7T+33Ok7AS9Zkxi0fR/1367NkxxL+1eVfLBm4hCsqXOF1NGPyHckPQ5tGRkZqbGys1zH+YvPBzUS8G8GjLR/ljRve8DpOwNp8cDP3fHUPP/7+I9dfej3jbx5PrTK1vI5lTMgTkZWq+peBaQL25Hh+cHmFy7mz0Z28G/sue07s8TpOwDmfdJ6Xf3yZxu83ZsP+DUzsNpE5/eZY0TDGY1Y4PDb82uEkJify4pIXvY4SUOL2xtHyw5Y8/cPT3HzZzWx8aCP9m/S3diHGBAArHB67pOwl3N3kbj5Y9QG/H/vd6zieO5t4lmd/eJbmHzRnz4k9zOg1gxm9Z1C5RGWvoxljXFY4AsBzbZ8DYPTi0R4n8dZPv/9Ek/eb8OKPL3JX47vY+NBGekT08DqWMSYNKxwBoHrp6tx35X3ExMWw5fAWr+PkuZMJJ3nku0do8+82nE08y9w75hLTLYZyRct5Hc0Y44MVjgDx9DVPU7BAQaIWR3kdJU/NjZ9L/Xfr887yd/h7i7+z/sH1XH/p9V7HMsZkwApHgLi45MU81PwhPl77Mb8e/NXrOH53+MxhBnwxgM6fdKZYwWIsGbiEt7u8TYlCJbyOZozJhBWOAPJk6ycpGl6UEQtHeB3Fr2ZunEnEuAg+Xvsxz7Z5lrj74mhdo7XXsYwxWWSFI4BULF6RIS2H8NmGz1i7b63XcXLd3hN76TGtBz2n96RqqarEDo5ldIfR1pTQmCBjhSPAPHH1E5QuXJrnFz7vdZRco6pMXD2RiHcj+Oa3b3i548ssu2cZTSo38TqaMeYCWOEIMGWLluWxqx7ji1+/YOWelV7HybHtR7dzw8c3MPDLgTS8qCFrH1jLk9c8SXhYuNfRjDEXyApHAHq01aOUK1qOYQuGeR3lgiUlJzF22VgavNuAn3f9zLgbx7FwwEIuK3+Z19GMMTlkhSMAlSpciqFXD+W7+O/4eefPXsfJtk0HNtF2YluGzBlCm5pt2PDgBh5s/iBhYv/cjAkF9n9ygHq4xcNcVPyioNrrOJ90nhcWv0CT8U349eCvTO4+mW/7fkuN0jW8jmaMyUVWOAJU8ULFefqap/lh2w8s3L7Q6ziZWrV3Fc0/aM5zC56j+xXd2fjgRu5sfKc1JTQmBFnhCGD3R95PlZJVGLZgGIE6bsqZ82d46vunaPFBC/ad2ses22bxWc/PqFSiktfRjDF+YoUjgBUJL8KzbZ7lx99/ZN6WeV7H+YslO5bQZHwTXvnpFQY0GcDGBzfS/YruXscyxviZFY4AN6jpIGqWrhlQex3Hzx3noW8eou3EtpxPOs/3d37Ph10/pGzRsl5HM8bkASscAa5weGGGtR3Gij0r+Pq3r72Ow3f/+Y4G7zbgvdj3eLTlo6x7YB0dL+nodSxjTB6ywhEE7mp8F5eWvZRhC4aRrMmeZDh0+hB3zbqLGz+9kZKFS7J00FLGdB5D8ULFPcljjPGOFY4gULBAQUa0G8GafWv4fNPnebptVWXahmnUG1ePKeunMKztMFYNXkWraq3yNIcxJnBY4QgSfRr0oV6FegxfMJyk5KQ82eaeE3u4ddqt3DbjNmqUrsHKwSuJah9F4fDCebJ9Y0xgssIRJAqEFWBku5FsOriJqeun+nVbqkr0qmgixkUwJ34Or173Kr/c8wuNKjXy63aNMcHBCkcQ6RHRg0aVGjFi0QgSkxP9so2tR7bS6aNO3PPVPTSu3Ji196/ln63/aU0JjTH/ZYUjiIRJGFHtoog/HM/kNZNzdd1JyUm89ctbNHyvIct3L+f9m95nQf8F1C1fN1e3Y4wJflY4gkzXy7sSWSWSqEVRJCQl5Mo6N+zfQOuY1vxj7j9oX6s9Gx/ayH2R91lTQmOMT/bJEGREhFHtR7Hj2A5i4mJytK6EpARGLRpF0/FNiT8czye3fsJXfb6iWqlquZTWGBOKrHAEoRsuvYHW1VszevFoziaevaB1rNi9gsgJkQxfOJweET3Y9NAm+jbsa00JjTGZssIRhFL2Onaf2M342PHZeu7p86cZ+n9DaRXdikNnDvHl7V8ypccUKhav6Ke0xphQY4UjSLWv3Z72tdrz4o8vcirhVJaes2j7Ihq/35jXlr7GoKaD2PjgRrpe3tXPSY0xocYKRxAb1X4U+0/tZ9yKcRkud+zsMe7/+n7aTWpHsibzw10/MOFvEyhdpHQeJTXGhBK/Fg4R6Swim0UkXkSe8jG/sIh85s5fJiK13OmdRGSliKxz/3ZI9ZyF7jpXu7eL/PkaAlnrGq3pXKczr/70KsfPHfe5zDe/fUP9d+vzwaoPeKzVY6x7YB0danfwuawxxmSF3wqHiBQAxgFdgAigj4hEpFlsEHBEVesAY4BX3OkHgb+pakOgP/BRmuf1U9Um7m2/v15DMIhqF8WhM4d4+5e3/zT9wKkD9Pu8HzdPuZkyRcqw9O6lvHHDGxQrWMyjpMaYUOHPPY4WQLyqblXVBGAq0C3NMt2ASe79GUBHERFVjVPVPe70DUBREbEGST40r9qcbpd3442f3+DImSOoKlPXTyXi3Qimb5jOiGtHsOq+VbSs1tLrqMaYEOHPPhJVgZ2pHu8C0n56/XcZVU0UkWNAeZw9jhQ9gFWqei7VtH+LSBIwExitPkY4EpHBwGCAGjVq5PClBLao9lE0fr8xT//wNHtO7OGr376iRdUWRHeNpsFFDbyOZ4wJMQHdgEhE6uMcvro+1eR+qrpbREriFI47gb/031DVCcAEgMjIyMAYOs9PGlVqRO/6vRm/cjxFw4vyxvVvMKTlEAqEFfA6mjEmBPmzcOwGqqd6XM2d5muZXSISDpQGDgGISDVgFnCXqm5JeYKq7nb/nhCRT3EOieVu46Yg9Fqn16hcvDJ/b/l36pSr43UcY0wI8+c5jhVAXRGpLSKFgNuB2WmWmY1z8hugJzBfVVVEygDfAE+p6k8pC4tIuIhUcO8XBG4G1vvxNQSNGqVr8HaXt61oGGP8zm+FQ1UTgYeBucAmYJqqbhCRKBFJueosGigvIvHAY0DKT3YfBuoAw9P87LYwMFdE1gKrcfZYPvDXazDGGPNX4uO8csiJjIzU2NhYr2MYY0xQEZGVqhqZdrpdOW6MMSZbrHAYY4zJFiscxhhjssUKhzHGmGyxwmGMMSZbrHAYY4zJlnzxc1wROQDsuMCnV+DPvbMCWTBlheDKG0xZIbjyBlNWCK68Oc1aU1X/MjxovigcOSEisb5+xxyIgikrBFfeYMoKwZU3mLJCcOX1V1Y7VGWMMSZbrHAYY4zJFiscmZvgdYBsCKasEFx5gykrBFfeYMoKwZXXL1ntHIcxxphssT0OY4wx2WKFwxhjTLZY4UiHiBQRkeUiskZENojISK8zZUZECohInIh87XWWzIjIdhFZ5461EtA970WkjIjMEJFfRWSTiFzldSZfROTyVOPXrBaR4yLyqNe5MiIi/3D//1ovIlNEpIjXmdIjIkPcnBsC8X0VkRgR2S8i61NNKyci/yci/3H/ls2NbVnhSN85oIOqNgaaAJ1FpJXHmTIzBGfQrGDRXlWbBMFv4t8G5qjqFUBjAvQ9VtXN7vvZBLgSOI0z/HJAEpGqwCNApKo2AArgjBQacESkAXAvzlDVjYGbRSTQhtucCHROM+0p4AdVrQv8wP8Gy8sRKxzpUMdJ92FB9xawvyRwx2i/CfjQ6yyhRERKA21xRqtEVRNU9ai3qbKkI7BFVS+0Y0JeCQeKikg4UAzY43Ge9NQDlqnqaXd000XArR5n+hNVXQwcTjO5GzDJvT8J6J4b27LCkQH30M9qYD/wf6q6zOtMGXgLGAokex0kixSYJyIrRWSw12EyUBs4APzbPQz4oYgU9zpUFtwOTPE6REZUdTfwOvA7sBc4pqrzvE2VrvVAGxEpLyLFgBuB6h5nyopKqrrXvf8HUCk3VmqFIwOqmuTu9lcDWri7qwFHRG4G9qvqSq+zZMM1qtoM6AI8JCJtvQ6UjnCgGfCeqjYFTpFLu/v+IiKFgK7AdK+zZMQ93t4NpzhXAYqLyB3epvJNVTcBrwDzgDnAaiDJ01DZpM61F7ly1MQKRxa4hyYW8Nfjh4GiNdBVRLYDU4EOIvKxt5Ey5n7bRFX34xyHb+FtonTtAnal2tucgVNIAlkXYJWq7vM6SCauA7ap6gFVPQ98DlztcaZ0qWq0ql6pqm2BI8BvXmfKgn0icjGA+3d/bqzUCkc6RKSiiJRx7xcFOgG/epvKN1V9WlWrqWotnEMU81U1IL+5AYhIcREpmXIfuB7nUEDAUdU/gJ0icrk7qSOw0cNIWdGHAD9M5fodaCUixUREcN7bgPzhAYCIXOT+rYFzfuNTbxNlyWygv3u/P/Blbqw0PDdWEqIuBiaJSAGcAjtNVQP+Z65BohIwy/msIBz4VFXneBspQ38HPnEPAW0FBnqcJ11uIe4E3Od1lsyo6jIRmQGsAhKBOAK7ncdMESkPnAceCrQfSYjIFKAdUEFEdgHPAy8D00RkEM7QEr1zZVvWcsQYY0x22KEqY4wx2WKFwxhjTLZY4TDGGJMtVjiMMcZkixUOY4wx2WKFwxgfRERTX0QpIuEiciA3Og+LSDsROea2MNksIovdq/8vdH21RKRvqscDROSdnOY0Jj1WOIzx7RTQwL34E5xrI3bn4vqXqGpTVb0cp0PsOyLS8QLXVQvom9lCxuQWKxzGpO9bnI7DkOZqbBFpISI/u3sNS1OuLHfHl4hx7zd0x28oltFGVHU1EAU87D6voojMFJEV7q21O32EiHzkbvc/InKvu4qXcRrwrRaRf7jTqojIHHe5V3Pn7TDGYYXDmPRNBW53BxdqBKTujvwr0MZtfDgceNGd/jZQR0RuAf4N3Keqp7OwrVXAFanWMUZVmwM9+HOr/EZAB+AqYLiIVMFpurjEHYtjjLtcE+A2oCFwm4gEQydXEySs5Ygx6VDVtSJSC2dv49s0s0vjtKSpi9NxtKD7nGQRGQCsBcar6k9Z3Jykun8dEOG2ZAEoJSIl3PtfquoZ4IyILMBpDumr9cUPqnoMQEQ2AjWBnVnMYkyGrHAYk7HZOGNGtAPKp5o+Cligqre4xWVhqnl1gZM4rcKzqin/a/AXBrRS1bOpF3ALSdoeQen1DDqX6n4S9v+6yUV2qMqYjMUAI1V1XZrppfnfyfIBKRPdEQPH4owaWF5Eema2ARFpBAwDxrmT5uE0VkyZ3yTV4t1EpIjbbK8dsAI4AZTM+ksyJmescBiTAVXdpapjfcx6FXhJROL487f5McA4Vf0NGAS8nNKOO402KT/HxSkYj6jqD+68R4BIEVnrHma6P9Xz1uKMDfMLMEpV97jTkkRkTaqT48b4jXXHNSZIiMgI4KSqvu51FpO/2R6HMcaYbLE9DmOMMdliexzGGGOyxQqHMcaYbLHCYYwxJluscBhjjMkWKxzGGGOy5f8B/1aDZctdTYsAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_data = tree.export_graphviz(decision_tree[5], out_file=None) \n",
        "graph = graphviz.Source(graph_data) \n",
        "graph.render(\"Breast Cancer\")\n",
        "graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "AUeNNxR0gxO6",
        "outputId": "1039e5ed-563a-44c9-e3fb-b73540362004"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f8c81e41b50>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"1144pt\" height=\"581pt\"\n viewBox=\"0.00 0.00 1143.50 581.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 577)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-577 1139.5,-577 1139.5,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"556,-573 424,-573 424,-505 556,-505 556,-573\"/>\n<text text-anchor=\"middle\" x=\"490\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[2] &lt;= 2.5</text>\n<text text-anchor=\"middle\" x=\"490\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.986</text>\n<text text-anchor=\"middle\" x=\"490\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 400</text>\n<text text-anchor=\"middle\" x=\"490\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [228, 172]</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"431,-469 315,-469 315,-401 431,-401 431,-469\"/>\n<text text-anchor=\"middle\" x=\"373\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[0] &lt;= 5.5</text>\n<text text-anchor=\"middle\" x=\"373\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.19</text>\n<text text-anchor=\"middle\" x=\"373\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 206</text>\n<text text-anchor=\"middle\" x=\"373\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [200, 6]</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M451.6898,-504.9465C441.2859,-495.6986 429.911,-485.5876 419.1243,-475.9994\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"421.1956,-473.1577 411.3962,-469.13 416.5451,-478.3896 421.1956,-473.1577\"/>\n<text text-anchor=\"middle\" x=\"412.8643\" y=\"-490.3869\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"685,-469 561,-469 561,-401 685,-401 685,-469\"/>\n<text text-anchor=\"middle\" x=\"623\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[5] &lt;= 2.5</text>\n<text text-anchor=\"middle\" x=\"623\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.595</text>\n<text text-anchor=\"middle\" x=\"623\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 194</text>\n<text text-anchor=\"middle\" x=\"623\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [28, 166]</text>\n</g>\n<!-- 0&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>0&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M533.5492,-504.9465C545.6054,-495.519 558.8089,-485.1946 571.2816,-475.4415\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"573.6314,-478.0471 579.353,-469.13 569.3194,-472.5328 573.6314,-478.0471\"/>\n<text text-anchor=\"middle\" x=\"576.3166\" y=\"-490.2449\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"248,-365 130,-365 130,-297 248,-297 248,-365\"/>\n<text text-anchor=\"middle\" x=\"189\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[5] &lt;= 4.5</text>\n<text text-anchor=\"middle\" x=\"189\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.046</text>\n<text text-anchor=\"middle\" x=\"189\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 197</text>\n<text text-anchor=\"middle\" x=\"189\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [196, 1]</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M314.7813,-402.0938C296.4212,-391.7164 275.9768,-380.1608 256.9976,-369.4335\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"258.5326,-366.2807 248.1047,-364.407 255.0882,-372.3746 258.5326,-366.2807\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"432,-365 314,-365 314,-297 432,-297 432,-365\"/>\n<text text-anchor=\"middle\" x=\"373\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[5] &lt;= 1.5</text>\n<text text-anchor=\"middle\" x=\"373\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.991</text>\n<text text-anchor=\"middle\" x=\"373\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 9</text>\n<text text-anchor=\"middle\" x=\"373\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [4, 5]</text>\n</g>\n<!-- 1&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>1&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M373,-400.9465C373,-392.776 373,-383.9318 373,-375.3697\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"376.5001,-375.13 373,-365.13 369.5001,-375.13 376.5001,-375.13\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"116,-253.5 0,-253.5 0,-200.5 116,-200.5 116,-253.5\"/>\n<text text-anchor=\"middle\" x=\"58\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"58\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 191</text>\n<text text-anchor=\"middle\" x=\"58\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [191, 0]</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M146.1057,-296.9465C131.1212,-285.0504 114.3376,-271.726 99.4712,-259.9237\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"101.4411,-257.0187 91.4329,-253.5422 97.0887,-262.5011 101.4411,-257.0187\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"244,-261 134,-261 134,-193 244,-193 244,-261\"/>\n<text text-anchor=\"middle\" x=\"189\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[0] &lt;= 3.5</text>\n<text text-anchor=\"middle\" x=\"189\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.65</text>\n<text text-anchor=\"middle\" x=\"189\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 6</text>\n<text text-anchor=\"middle\" x=\"189\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [5, 1]</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M189,-296.9465C189,-288.776 189,-279.9318 189,-271.3697\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"192.5001,-271.13 189,-261.13 185.5001,-271.13 192.5001,-271.13\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"180.5,-149.5 79.5,-149.5 79.5,-96.5 180.5,-96.5 180.5,-149.5\"/>\n<text text-anchor=\"middle\" x=\"130\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"130\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5</text>\n<text text-anchor=\"middle\" x=\"130\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [5, 0]</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M169.6812,-192.9465C163.4324,-181.9316 156.4888,-169.6922 150.1793,-158.5703\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"153.0362,-156.513 145.0576,-149.5422 146.9477,-159.967 153.0362,-156.513\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"299.5,-149.5 198.5,-149.5 198.5,-96.5 299.5,-96.5 299.5,-149.5\"/>\n<text text-anchor=\"middle\" x=\"249\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"249\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"249\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1]</text>\n</g>\n<!-- 4&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>4&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M208.6462,-192.9465C215.0645,-181.8215 222.2035,-169.4473 228.671,-158.237\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"231.7216,-159.9531 233.6872,-149.5422 225.6583,-156.455 231.7216,-159.9531\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"363.5,-253.5 262.5,-253.5 262.5,-200.5 363.5,-200.5 363.5,-253.5\"/>\n<text text-anchor=\"middle\" x=\"313\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"313\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4</text>\n<text text-anchor=\"middle\" x=\"313\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [4, 0]</text>\n</g>\n<!-- 7&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>7&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M353.3538,-296.9465C346.9355,-285.8215 339.7965,-273.4473 333.329,-262.237\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"336.3417,-260.455 328.3128,-253.5422 330.2784,-263.9531 336.3417,-260.455\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"482.5,-253.5 381.5,-253.5 381.5,-200.5 482.5,-200.5 482.5,-253.5\"/>\n<text text-anchor=\"middle\" x=\"432\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"432\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5</text>\n<text text-anchor=\"middle\" x=\"432\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 5]</text>\n</g>\n<!-- 7&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>7&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M392.3188,-296.9465C398.5676,-285.9316 405.5112,-273.6922 411.8207,-262.5703\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"415.0523,-263.967 416.9424,-253.5422 408.9638,-260.513 415.0523,-263.967\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"682,-365 564,-365 564,-297 682,-297 682,-365\"/>\n<text text-anchor=\"middle\" x=\"623\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[4] &lt;= 4.5</text>\n<text text-anchor=\"middle\" x=\"623\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.974</text>\n<text text-anchor=\"middle\" x=\"623\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 32</text>\n<text text-anchor=\"middle\" x=\"623\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [19, 13]</text>\n</g>\n<!-- 10&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>10&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M623,-400.9465C623,-392.776 623,-383.9318 623,-375.3697\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"626.5001,-375.13 623,-365.13 619.5001,-375.13 626.5001,-375.13\"/>\n</g>\n<!-- 16 -->\n<g id=\"node17\" class=\"node\">\n<title>16</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"880,-365 764,-365 764,-297 880,-297 880,-365\"/>\n<text text-anchor=\"middle\" x=\"822\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[0] &lt;= 6.5</text>\n<text text-anchor=\"middle\" x=\"822\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.31</text>\n<text text-anchor=\"middle\" x=\"822\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 162</text>\n<text text-anchor=\"middle\" x=\"822\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [9, 153]</text>\n</g>\n<!-- 10&#45;&gt;16 -->\n<g id=\"edge16\" class=\"edge\">\n<title>10&#45;&gt;16</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M685.1463,-402.5215C707.1971,-390.9975 732.1113,-377.977 754.5811,-366.234\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"756.474,-369.194 763.7155,-361.4602 753.2317,-362.9901 756.474,-369.194\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"619,-261 501,-261 501,-193 619,-193 619,-261\"/>\n<text text-anchor=\"middle\" x=\"560\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[0] &lt;= 8.5</text>\n<text text-anchor=\"middle\" x=\"560\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.286</text>\n<text text-anchor=\"middle\" x=\"560\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 20</text>\n<text text-anchor=\"middle\" x=\"560\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [19, 1]</text>\n</g>\n<!-- 11&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>11&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M602.3714,-296.9465C597.1501,-288.3271 591.4745,-278.9579 586.0245,-269.9611\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"588.8497,-267.8697 580.6749,-261.13 582.8626,-271.4965 588.8497,-267.8697\"/>\n</g>\n<!-- 15 -->\n<g id=\"node16\" class=\"node\">\n<title>15</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"744.5,-253.5 637.5,-253.5 637.5,-200.5 744.5,-200.5 744.5,-253.5\"/>\n<text text-anchor=\"middle\" x=\"691\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"691\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 12</text>\n<text text-anchor=\"middle\" x=\"691\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 12]</text>\n</g>\n<!-- 11&#45;&gt;15 -->\n<g id=\"edge15\" class=\"edge\">\n<title>11&#45;&gt;15</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M645.2657,-296.9465C652.5398,-285.8215 660.6306,-273.4473 667.9604,-262.237\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"671.1024,-263.8273 673.6455,-253.5422 665.2436,-259.9965 671.1024,-263.8273\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"492.5,-149.5 385.5,-149.5 385.5,-96.5 492.5,-96.5 492.5,-149.5\"/>\n<text text-anchor=\"middle\" x=\"439\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"439\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 19</text>\n<text text-anchor=\"middle\" x=\"439\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [19, 0]</text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>12&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M520.3801,-192.9465C506.6676,-181.1606 491.3239,-167.9726 477.6873,-156.2519\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"479.7459,-153.4061 469.8808,-149.5422 475.1831,-158.7147 479.7459,-153.4061\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"611.5,-149.5 510.5,-149.5 510.5,-96.5 611.5,-96.5 611.5,-149.5\"/>\n<text text-anchor=\"middle\" x=\"561\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"561\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"561\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1]</text>\n</g>\n<!-- 12&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>12&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M560.3274,-192.9465C560.4302,-182.2621 560.544,-170.4254 560.6483,-159.5742\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"564.1484,-159.5754 560.7448,-149.5422 557.1487,-159.508 564.1484,-159.5754\"/>\n</g>\n<!-- 17 -->\n<g id=\"node18\" class=\"node\">\n<title>17</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"881,-261 763,-261 763,-193 881,-193 881,-261\"/>\n<text text-anchor=\"middle\" x=\"822\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[3] &lt;= 5.5</text>\n<text text-anchor=\"middle\" x=\"822\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.544</text>\n<text text-anchor=\"middle\" x=\"822\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 64</text>\n<text text-anchor=\"middle\" x=\"822\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [8, 56]</text>\n</g>\n<!-- 16&#45;&gt;17 -->\n<g id=\"edge17\" class=\"edge\">\n<title>16&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M822,-296.9465C822,-288.776 822,-279.9318 822,-271.3697\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"825.5001,-271.13 822,-261.13 818.5001,-271.13 825.5001,-271.13\"/>\n</g>\n<!-- 22 -->\n<g id=\"node23\" class=\"node\">\n<title>22</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"1017,-261 899,-261 899,-193 1017,-193 1017,-261\"/>\n<text text-anchor=\"middle\" x=\"958\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[2] &lt;= 4.5</text>\n<text text-anchor=\"middle\" x=\"958\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.082</text>\n<text text-anchor=\"middle\" x=\"958\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 98</text>\n<text text-anchor=\"middle\" x=\"958\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 97]</text>\n</g>\n<!-- 16&#45;&gt;22 -->\n<g id=\"edge22\" class=\"edge\">\n<title>16&#45;&gt;22</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M866.5315,-296.9465C878.8597,-287.519 892.3609,-277.1946 905.115,-267.4415\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"907.551,-269.9848 913.3685,-261.13 903.2988,-264.4243 907.551,-269.9848\"/>\n</g>\n<!-- 18 -->\n<g id=\"node19\" class=\"node\">\n<title>18</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"752,-157 634,-157 634,-89 752,-89 752,-157\"/>\n<text text-anchor=\"middle\" x=\"693\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[7] &lt;= 7.5</text>\n<text text-anchor=\"middle\" x=\"693\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.799</text>\n<text text-anchor=\"middle\" x=\"693\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 33</text>\n<text text-anchor=\"middle\" x=\"693\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [8, 25]</text>\n</g>\n<!-- 17&#45;&gt;18 -->\n<g id=\"edge18\" class=\"edge\">\n<title>17&#45;&gt;18</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M779.7606,-192.9465C768.0669,-183.519 755.2606,-173.1946 743.163,-163.4415\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"745.3162,-160.6816 735.3343,-157.13 740.9227,-166.1312 745.3162,-160.6816\"/>\n</g>\n<!-- 21 -->\n<g id=\"node22\" class=\"node\">\n<title>21</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"877.5,-149.5 770.5,-149.5 770.5,-96.5 877.5,-96.5 877.5,-149.5\"/>\n<text text-anchor=\"middle\" x=\"824\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"824\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 31</text>\n<text text-anchor=\"middle\" x=\"824\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 31]</text>\n</g>\n<!-- 17&#45;&gt;21 -->\n<g id=\"edge21\" class=\"edge\">\n<title>17&#45;&gt;21</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M822.6549,-192.9465C822.8603,-182.2621 823.088,-170.4254 823.2966,-159.5742\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"826.7966,-159.6076 823.4896,-149.5422 819.7979,-159.473 826.7966,-159.6076\"/>\n</g>\n<!-- 19 -->\n<g id=\"node20\" class=\"node\">\n<title>19</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"689,-53 579,-53 579,0 689,0 689,-53\"/>\n<text text-anchor=\"middle\" x=\"634\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.89</text>\n<text text-anchor=\"middle\" x=\"634\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 26</text>\n<text text-anchor=\"middle\" x=\"634\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [8, 18]</text>\n</g>\n<!-- 18&#45;&gt;19 -->\n<g id=\"edge19\" class=\"edge\">\n<title>18&#45;&gt;19</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M672.1988,-88.9777C666.8242,-80.187 661.0265,-70.7044 655.6115,-61.8477\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"658.5564,-59.9545 650.354,-53.2485 652.5842,-63.6059 658.5564,-59.9545\"/>\n</g>\n<!-- 20 -->\n<g id=\"node21\" class=\"node\">\n<title>20</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"808.5,-53 707.5,-53 707.5,0 808.5,0 808.5,-53\"/>\n<text text-anchor=\"middle\" x=\"758\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"758\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 7</text>\n<text text-anchor=\"middle\" x=\"758\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 7]</text>\n</g>\n<!-- 18&#45;&gt;20 -->\n<g id=\"edge20\" class=\"edge\">\n<title>18&#45;&gt;20</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M715.9166,-88.9777C721.8994,-80.0954 728.3582,-70.5067 734.377,-61.5711\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"737.2991,-63.4978 739.9829,-53.2485 731.4933,-59.5871 737.2991,-63.4978\"/>\n</g>\n<!-- 23 -->\n<g id=\"node24\" class=\"node\">\n<title>23</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"1010,-157 900,-157 900,-89 1010,-89 1010,-157\"/>\n<text text-anchor=\"middle\" x=\"955\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[7] &lt;= 7.0</text>\n<text text-anchor=\"middle\" x=\"955\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.25</text>\n<text text-anchor=\"middle\" x=\"955\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 24</text>\n<text text-anchor=\"middle\" x=\"955\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 23]</text>\n</g>\n<!-- 22&#45;&gt;23 -->\n<g id=\"edge23\" class=\"edge\">\n<title>22&#45;&gt;23</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M957.0177,-192.9465C956.782,-184.776 956.5269,-175.9318 956.2799,-167.3697\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"959.7715,-167.0249 955.9845,-157.13 952.7744,-167.2268 959.7715,-167.0249\"/>\n</g>\n<!-- 26 -->\n<g id=\"node27\" class=\"node\">\n<title>26</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"1135.5,-149.5 1028.5,-149.5 1028.5,-96.5 1135.5,-96.5 1135.5,-149.5\"/>\n<text text-anchor=\"middle\" x=\"1082\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"1082\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 74</text>\n<text text-anchor=\"middle\" x=\"1082\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 74]</text>\n</g>\n<!-- 22&#45;&gt;26 -->\n<g id=\"edge26\" class=\"edge\">\n<title>22&#45;&gt;26</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M998.6022,-192.9465C1012.6547,-181.1606 1028.3788,-167.9726 1042.3535,-156.2519\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1044.9408,-158.65 1050.3536,-149.5422 1040.4425,-153.2866 1044.9408,-158.65\"/>\n</g>\n<!-- 24 -->\n<g id=\"node25\" class=\"node\">\n<title>24</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"935.5,-53 828.5,-53 828.5,0 935.5,0 935.5,-53\"/>\n<text text-anchor=\"middle\" x=\"882\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"882\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 19</text>\n<text text-anchor=\"middle\" x=\"882\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 19]</text>\n</g>\n<!-- 23&#45;&gt;24 -->\n<g id=\"edge24\" class=\"edge\">\n<title>23&#45;&gt;24</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M929.2629,-88.9777C922.4744,-80.0039 915.1404,-70.3089 908.3216,-61.295\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"911.059,-59.1121 902.2346,-53.2485 905.4763,-63.3352 911.059,-59.1121\"/>\n</g>\n<!-- 25 -->\n<g id=\"node26\" class=\"node\">\n<title>25</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"1072,-53 954,-53 954,0 1072,0 1072,-53\"/>\n<text text-anchor=\"middle\" x=\"1013\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.722</text>\n<text text-anchor=\"middle\" x=\"1013\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5</text>\n<text text-anchor=\"middle\" x=\"1013\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 4]</text>\n</g>\n<!-- 23&#45;&gt;25 -->\n<g id=\"edge25\" class=\"edge\">\n<title>23&#45;&gt;25</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M975.4486,-88.9777C980.7322,-80.187 986.4316,-70.7044 991.7548,-61.8477\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"994.7715,-63.6225 996.9232,-53.2485 988.7718,-60.0165 994.7715,-63.6225\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jZTHMPeIhDCo"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 1 (f) AdaBoost, XGBoost and Random Forest**"
      ],
      "metadata": {
        "id": "9V18rn37hEzV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adaboost**"
      ],
      "metadata": {
        "id": "XIO7E3jBkUAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "classifier_ADB = []\n",
        "MCR_ADB = []\n",
        "weighted_cost_ADB = []\n",
        "\n",
        "for   wl in [100,200,300,400,500]:\n",
        "  classifier_ADB_ = AdaBoostClassifier(n_estimators=wl)\n",
        "  classifier_ADB_.fit(train_data,train_label)\n",
        "  classifier_ADB.append(classifier_ADB_)\n",
        "\n",
        "  test_pred_ADB = classifier_ADB_.predict(test_data)\n",
        "\n",
        "  mcr_ADB , comparison_ADB = miss_classification_rate(test_pred_ADB)\n",
        "  MCR_ADB.append(mcr_ADB)\n",
        "\n",
        "  print(\"-----AdaBoost with\", wl , \" weak learnners-----\")\n",
        "  print()\n",
        "  print(\"Number of Miss Classification : \"  ,  283 - np.count_nonzero(comparison_ADB))\n",
        "  print(\"Miss classification rate (MCR): \", mcr_ADB)\n",
        "  print()\n",
        "\n",
        "  # \"\"\"*** Weighted Cost ADB***\"\"\"\n",
        "  weighted_cost_ADB.append(weighted_cost(comparison_ADB)) \n",
        "\n",
        "  print(\"***** Weighted Cost of ADB *****\\n\")\n",
        "  print(weighted_cost_ADB[int(wl/100)-1])\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8z8jD9_hLnc",
        "outputId": "5dd674ae-4a7e-4835-869a-64753255470c"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----AdaBoost with 100  weak learnners-----\n",
            "\n",
            "Number of Miss Classification :  11\n",
            "Miss classification rate (MCR):  0.03886925795053009\n",
            "\n",
            "***** Weighted Cost of ADB *****\n",
            "\n",
            "0.10179294389820705\n",
            "\n",
            "-----AdaBoost with 200  weak learnners-----\n",
            "\n",
            "Number of Miss Classification :  11\n",
            "Miss classification rate (MCR):  0.03886925795053009\n",
            "\n",
            "***** Weighted Cost of ADB *****\n",
            "\n",
            "0.10179294389820705\n",
            "\n",
            "-----AdaBoost with 300  weak learnners-----\n",
            "\n",
            "Number of Miss Classification :  14\n",
            "Miss classification rate (MCR):  0.04946996466431097\n",
            "\n",
            "***** Weighted Cost of ADB *****\n",
            "\n",
            "0.14517061885482938\n",
            "\n",
            "-----AdaBoost with 400  weak learnners-----\n",
            "\n",
            "Number of Miss Classification :  11\n",
            "Miss classification rate (MCR):  0.03886925795053009\n",
            "\n",
            "***** Weighted Cost of ADB *****\n",
            "\n",
            "0.10179294389820705\n",
            "\n",
            "-----AdaBoost with 500  weak learnners-----\n",
            "\n",
            "Number of Miss Classification :  12\n",
            "Miss classification rate (MCR):  0.04240282685512364\n",
            "\n",
            "***** Weighted Cost of ADB *****\n",
            "\n",
            "0.11625216888374783\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGBoost Classifier**"
      ],
      "metadata": {
        "id": "C26jB9cpo-9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost.sklearn import XGBClassifier\n",
        "\n",
        "classifier_XGB = []\n",
        "MCR_XGB = []\n",
        "weighted_cost_XGB = []\n",
        "\n",
        "for   wl in [100,200,300,400,500]:\n",
        "  classifier_XGB_ = AdaBoostClassifier(n_estimators=wl)\n",
        "  classifier_XGB_.fit(train_data,train_label)\n",
        "  classifier_XGB.append(classifier_XGB_)\n",
        "\n",
        "  test_pred_XGB = classifier_XGB_.predict(test_data)\n",
        "\n",
        "  mcr_XGB , comparison_XGB = miss_classification_rate(test_pred_XGB)\n",
        "  MCR_XGB.append(mcr_XGB)\n",
        "\n",
        "  print(\"-----XGboost with\", wl , \" weak learnners-----\")\n",
        "  print()\n",
        "  print(\"Number of Miss Classification : \"  ,  283 - np.count_nonzero(comparison_XGB))\n",
        "  print(\"Miss classification rate (MCR): \", mcr_XGB)\n",
        "  print()\n",
        "\n",
        "  # \"\"\"*** Weighted Cost XGB***\"\"\"\n",
        "  weighted_cost_XGB.append(weighted_cost(comparison_XGB)) \n",
        "\n",
        "  print(\"***** Weighted Cost of XGB *****\\n\")\n",
        "  print(weighted_cost_XGB[int(wl/100)-1])\n",
        "  print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiHrvFsDo4Zf",
        "outputId": "ba5dd5dc-f118-482b-a2a3-73a0f06cb79a"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----XGboost with 100  weak learnners-----\n",
            "\n",
            "Number of Miss Classification :  11\n",
            "Miss classification rate (MCR):  0.03886925795053009\n",
            "\n",
            "***** Weighted Cost of XGB *****\n",
            "\n",
            "0.10179294389820705\n",
            "\n",
            "-----XGboost with 200  weak learnners-----\n",
            "\n",
            "Number of Miss Classification :  11\n",
            "Miss classification rate (MCR):  0.03886925795053009\n",
            "\n",
            "***** Weighted Cost of XGB *****\n",
            "\n",
            "0.10179294389820705\n",
            "\n",
            "-----XGboost with 300  weak learnners-----\n",
            "\n",
            "Number of Miss Classification :  14\n",
            "Miss classification rate (MCR):  0.04946996466431097\n",
            "\n",
            "***** Weighted Cost of XGB *****\n",
            "\n",
            "0.14517061885482938\n",
            "\n",
            "-----XGboost with 400  weak learnners-----\n",
            "\n",
            "Number of Miss Classification :  11\n",
            "Miss classification rate (MCR):  0.03886925795053009\n",
            "\n",
            "***** Weighted Cost of XGB *****\n",
            "\n",
            "0.10179294389820705\n",
            "\n",
            "-----XGboost with 500  weak learnners-----\n",
            "\n",
            "Number of Miss Classification :  12\n",
            "Miss classification rate (MCR):  0.04240282685512364\n",
            "\n",
            "***** Weighted Cost of XGB *****\n",
            "\n",
            "0.11625216888374783\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest Classifier**"
      ],
      "metadata": {
        "id": "2TnnjA1bmx0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "classifier_RF = []\n",
        "MCR_RF = []\n",
        "weighted_cost_RF = []\n",
        "\n",
        "for   wl in [100,200,300,400,500]:\n",
        "  classifier_RF_ = AdaBoostClassifier(n_estimators=wl)\n",
        "  classifier_RF_.fit(train_data,train_label)\n",
        "  classifier_RF.append(classifier_RF_)\n",
        "\n",
        "  test_pred_RF = classifier_RF_.predict(test_data)\n",
        "\n",
        "  mcr_RF , comparison_RF = miss_classification_rate(test_pred_RF)\n",
        "  MCR_RF.append(mcr_RF)\n",
        "\n",
        "  print(\"-----Random Forrest with\", wl , \" weak learnners-----\")\n",
        "  print()\n",
        "  print(\"Number of Miss Classification : \"  ,  283 - np.count_nonzero(comparison_RF))\n",
        "  print(\"Miss classification rate (MCR): \", mcr_RF)\n",
        "  print()\n",
        "\n",
        "  # \"\"\"*** Weighted Cost RF***\"\"\"\n",
        "  weighted_cost_RF.append(weighted_cost(comparison_RF)) \n",
        "\n",
        "  print(\"***** Weighted Cost of RF *****\\n\")\n",
        "  print(weighted_cost_RF[int(wl/100)-1])\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vL4gRKmbmwyJ",
        "outputId": "89c9c4b5-e016-4ba6-a825-b4e17dd3c0b6"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----Random Forrest with 100  weak learnners-----\n",
            "\n",
            "Number of Miss Classification :  11\n",
            "Miss classification rate (MCR):  0.03886925795053009\n",
            "\n",
            "***** Weighted Cost of RF *****\n",
            "\n",
            "0.10179294389820705\n",
            "\n",
            "-----Random Forrest with 200  weak learnners-----\n",
            "\n",
            "Number of Miss Classification :  11\n",
            "Miss classification rate (MCR):  0.03886925795053009\n",
            "\n",
            "***** Weighted Cost of RF *****\n",
            "\n",
            "0.10179294389820705\n",
            "\n",
            "-----Random Forrest with 300  weak learnners-----\n",
            "\n",
            "Number of Miss Classification :  14\n",
            "Miss classification rate (MCR):  0.04946996466431097\n",
            "\n",
            "***** Weighted Cost of RF *****\n",
            "\n",
            "0.14517061885482938\n",
            "\n",
            "-----Random Forrest with 400  weak learnners-----\n",
            "\n",
            "Number of Miss Classification :  11\n",
            "Miss classification rate (MCR):  0.03886925795053009\n",
            "\n",
            "***** Weighted Cost of RF *****\n",
            "\n",
            "0.10179294389820705\n",
            "\n",
            "-----Random Forrest with 500  weak learnners-----\n",
            "\n",
            "Number of Miss Classification :  12\n",
            "Miss classification rate (MCR):  0.04240282685512364\n",
            "\n",
            "***** Weighted Cost of RF *****\n",
            "\n",
            "0.11625216888374783\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 1 (f) Weighted Cost**"
      ],
      "metadata": {
        "id": "44W9Ly7rV8sM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In terms of **Miss Classification Rate (MCR)** Logistic Regression and kNN classifier with 6,8,9 and 10 nearest neighbour performs the best. With *MCR=0.010600706713780883* where only 3 test data were mis-classified.\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "NTugNNFXVTQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In terms of **Weighted Cost** kNN classifier with *k=3* is the best with weighted cost = 0.000578368999421631. So it misclassified 5 healty instances."
      ],
      "metadata": {
        "id": "nrWJsSUYX2Bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"***Logistic Regression***\")\n",
        "print(\"MCR : \", MCR_LR, \"\\nWeighted Cost : \", weighted_cost_LR)\n",
        "print()\n",
        "\n",
        "print(\"***KNN***\")\n",
        "print(\"MCR : \", MCR_knn)\n",
        "print(\"Weighted Cost : \", weighted_cost_KNN)\n",
        "print()\n",
        "\n",
        "print(\"***LDA***\")\n",
        "print(\"MCR : \", MCR_LDA)\n",
        "print(\"Weighted Cost : \" , weighted_cost_LDA)\n",
        "print()\n",
        "\n",
        "print(\"***SVM Linear***\")\n",
        "print(\"MCR : \", MCR_SVM_lin)\n",
        "print(\"Weighted Cost : \", weighted_cost_SVM_lin)\n",
        "print()\n",
        "\n",
        "print(\"***SVM Poly***\")\n",
        "print(\"MCR : \", MCR_SVM_poly)\n",
        "print(\"Weighted Cost : \", weighted_cost_SVM_poly)\n",
        "print()\n",
        "\n",
        "print(\"***SVM RBF***\")\n",
        "print(\"MCR : \", MCR_SVM_rbf)\n",
        "print(\"Weighted Cost : \", weighted_cost_SVM_rbf)\n",
        "print()\n",
        "\n",
        "print(\"***SVM Sigmoid***\")\n",
        "print(\"MCR : \", MCR_SVM_sig)\n",
        "print(\"Weighted Cost : \", weighted_cost_SVM_sig)\n",
        "print()\n",
        "\n",
        "print(\"***Decision Tree***\")\n",
        "print(\"MCR : \", MCR_DT)\n",
        "print(\"Weighted Cost : \", weighted_cost_DT)\n",
        "print()\n",
        "\n",
        "print(\"***AdaBoost***\")\n",
        "print(\"MCR : \", MCR_ADB)\n",
        "print(\"Weighted Cost : \", weighted_cost_ADB)\n",
        "print()\n",
        "\n",
        "print(\"***XGBoost***\")\n",
        "print(\"MCR : \", MCR_XGB)\n",
        "print(\"Weighted Cost : \", weighted_cost_XGB)\n",
        "print()\n",
        "\n",
        "print(\"***Random Forest***\")\n",
        "print(\"MCR : \", MCR_RF)\n",
        "print(\"Weighted Cost : \", weighted_cost_RF)\n",
        "print()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8BG3tG-WDxw",
        "outputId": "d5bf19df-e7d8-492e-d63a-9a0645322768"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***Logistic Regression***\n",
            "MCR :  0.010600706713780883 \n",
            "Weighted Cost :  0.01474840948525159\n",
            "\n",
            "***KNN***\n",
            "MCR :  [0.017667844522968212, 0.028268551236749095, 0.014134275618374548, 0.017667844522968212, 0.017667844522968212, 0.010600706713780883, 0.014134275618374548, 0.010600706713780883, 0.010600706713780883, 0.010600706713780883]\n",
            "Weighted Cost :  [0.015037593984962405, 0.08704453441295545, 0.000578368999421631, 0.029352226720647773, 0.015037593984962405, 0.01474840948525159, 0.014893001735106997, 0.01474840948525159, 0.01474840948525159, 0.01474840948525159]\n",
            "\n",
            "***LDA***\n",
            "MCR :  0.017667844522968212\n",
            "Weighted Cost :  0.0579814921920185\n",
            "\n",
            "***SVM Linear***\n",
            "MCR :  0.014134275618374548\n",
            "Weighted Cost :  0.014893001735106997\n",
            "\n",
            "***SVM Poly***\n",
            "MCR :  [0.014134275618374548, 0.014134275618374548, 0.014134275618374548, 0.014134275618374548]\n",
            "Weighted Cost :  [0.014893001735106997, 0.014893001735106997, 0.014893001735106997, 0.014893001735106997]\n",
            "\n",
            "***SVM RBF***\n",
            "MCR :  0.017667844522968212\n",
            "Weighted Cost :  0.015037593984962405\n",
            "\n",
            "***SVM Sigmoid***\n",
            "MCR :  0.017667844522968212\n",
            "Weighted Cost :  0.015037593984962405\n",
            "\n",
            "***Decision Tree***\n",
            "MCR :  [0.035335689045936425, 0.02473498233215543, 0.028268551236749095, 0.03180212014134276, 0.04240282685512364, 0.04240282685512364, 0.035335689045936425, 0.04946996466431097]\n",
            "Weighted Cost :  [0.0579814921920185, 0.0579814921920185, 0.0579814921920185, 0.0579814921920185, 0.0579814921920185, 0.0579814921920185, 0.0579814921920185, 0.0579814921920185]\n",
            "\n",
            "***AdaBoost***\n",
            "MCR :  [0.03886925795053009, 0.03886925795053009, 0.04946996466431097, 0.03886925795053009, 0.04240282685512364]\n",
            "Weighted Cost :  [0.10179294389820705, 0.10179294389820705, 0.14517061885482938, 0.10179294389820705, 0.11625216888374783]\n",
            "\n",
            "***XGBoost***\n",
            "MCR :  [0.03886925795053009, 0.03886925795053009, 0.04946996466431097, 0.03886925795053009, 0.04240282685512364]\n",
            "Weighted Cost :  [0.10179294389820705, 0.10179294389820705, 0.14517061885482938, 0.10179294389820705, 0.11625216888374783]\n",
            "\n",
            "***Random Forest***\n",
            "MCR :  [0.03886925795053009, 0.03886925795053009, 0.04946996466431097, 0.03886925795053009, 0.04240282685512364]\n",
            "Weighted Cost :  [0.10179294389820705, 0.10179294389820705, 0.14517061885482938, 0.10179294389820705, 0.11625216888374783]\n",
            "\n"
          ]
        }
      ]
    }
  ]
}