# -*- coding: utf-8 -*-
"""DA_HW2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-AvGw3RwdbXcsaoVpN-nbh2kx8N1V3Ra

Mount Google Drive
"""

#from google.colab import drive
#drive.mount('/content/drive')

import pandas as pd
import numpy as np
from sklearn.decomposition import PCA

#file_path = "/content/drive/MyDrive/Dataset/DA/HW2/url-data.txt"

file_path = "./url-data.txt"

df_data = pd.read_csv(file_path)

'''
with open(file_path) as f:
    data_txt = f.readlines()
'''

"""Pre-processing data"""

df_data.dropna()

df_train_data = df_data.iloc[:, 1:]

df_data_scaled = (df_train_data - df_train_data.mean()) / (df_train_data.std())

train_data = df_train_data.values
train_label = df_data.iloc[:, 0].values

train_data_scaled = df_data_scaled.values

"""**PCA for non-scaled data**"""

pca_full = PCA(n_components=64)
data_reduced = pca_full.fit_transform(train_data)

eigenvalues_full = pca_full.explained_variance_
variance_ratio_full = pca_full.explained_variance_ratio_

"""**Function for calculating minimum # principle components required from variance ratio**"""

def calc_min_principle_comp_required(variance_ratio, variance_ratio_threshold):
  
  maintained_variance_ratio = 0.0
  n = 1

  while maintained_variance_ratio < variance_ratio_threshold:

    maintained_variance_ratio = sum(variance_ratio[:n])
    n+=1

  return n-1

"""Calculating minimum # of principal components for **non-scaled data** from maintained variance ratio"""

principal_component_count_95 = calc_min_principle_comp_required(variance_ratio_full, 0.95)

principal_component_count_99 = calc_min_principle_comp_required(variance_ratio_full, 0.99)

print("For non-scaled data minimum # principal component required to maintaine 95% variance is : ",  principal_component_count_95)

print()

print("For non-scaled data minimum # principal component required to maintaine 99% variance is : ",  principal_component_count_99)

print()

"""**PCA for scaled data**"""

pca_full_scaled = PCA(n_components=64)
data_reduced_scaled = pca_full_scaled.fit_transform(train_data)

eigenvalues_full_scaled = pca_full_scaled.explained_variance_
variance_ratio_full_scaled = pca_full_scaled.explained_variance_ratio_

"""Calculating minimum # of principal components for **scaled data** from maintained variance ratio"""

principal_component_count_scaled_95 = calc_min_principle_comp_required(variance_ratio_full_scaled, 0.95)

principal_component_count_scaled_99 = calc_min_principle_comp_required(variance_ratio_full_scaled, 0.99)

print("For scaled data minimum # principal component required to maintaine 95% variance is : ",  principal_component_count_scaled_95)

print()

print("For scaled data minimum # principal component required to maintaine 99% variance is : ",  principal_component_count_scaled_99)

"""Scree plot for non-scaled data"""

import matplotlib.pyplot as plt

x = list(range(1, 65))

y = variance_ratio_full.tolist()

plt.plot(x, y, color='g')

# naming the x axis
plt.xlabel('i')
# naming the y axis
plt.ylabel("i th eigen value")
 
# giving a title to my graph
plt.title('Scree plot for non-scaled data')
 
# function to show the plot
plt.show()

"""Scree plot for scaled data"""

import matplotlib.pyplot as plt

x = list(range(1, 65))

y = variance_ratio_full_scaled.tolist()

plt.plot(x, y, color='b')

# naming the x axis
plt.xlabel('i')
# naming the y axis
plt.ylabel("i th eigen value")
 
# giving a title to my graph
plt.title('Scree plot for scaled data')
 
# function to show the plot
plt.show()